{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6d273-a3c3-46aa-be5e-015d7d82f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedList\n",
    "import gzip\n",
    "import shutil\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageColor\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, deque\n",
    "from scipy.ndimage import (\n",
    "    gaussian_filter,\n",
    "    label,\n",
    "    find_objects,\n",
    "    binary_dilation\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Concatenate, Conv2D, MaxPooling2D, UpSampling2D, concatenate,\n",
    "    BatchNormalization, Activation, Dense, Flatten, GlobalAveragePooling2D, Reshape\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984419b-8d01-491e-ac71-7d0b225c6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_dicts(file_path):\n",
    "    \"\"\"\n",
    "    Loads image dictionary data from a given file.\n",
    "    Parameters:\n",
    "        file_path (str): Path to the pickle file containing image dictionaries.\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing image metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return []\n",
    "\n",
    "# Define paths\n",
    "BASE_PATH = ''\n",
    "FILE_PATH = os.path.join(BASE_PATH, 'data\\\\image_dicts_256.pkl')\n",
    "EXCEL_FILE_PATH = 'data\\\\sample_groups.xlsx'\n",
    "\n",
    "# Load image dictionaries\n",
    "image_dicts = load_image_dicts(FILE_PATH)\n",
    "\n",
    "# Extract sample names from folders\n",
    "samples = []\n",
    "for tissue_type in ['Normal', 'Follicular', 'Papillary', 'Anaplastic']:\n",
    "    tissue_path = os.path.join(BASE_PATH, tissue_type)\n",
    "    if os.path.exists(tissue_path):\n",
    "        for subfolder in os.listdir(tissue_path):\n",
    "            if subfolder != \".DS_Store\":\n",
    "                samples.append(subfolder)\n",
    "    else:\n",
    "        print(f\"Warning: Path not found for tissue type '{tissue_type}'\")\n",
    "\n",
    "# Exclude specific samples\n",
    "EXCLUDE_LIST = [\"SSW-23-14395_C2\", \"SSW-23-05363_A7\"]\n",
    "image_dicts = [img for img in image_dicts if not any(excl in img[\"name\"] for excl in EXCLUDE_LIST)]\n",
    "\n",
    "def load_sample_groups(excel_file_path):\n",
    "    \"\"\"\n",
    "    Loads training, validation, and test sample groups from an Excel file.\n",
    "    Parameters:\n",
    "        excel_file_path (str): Path to the Excel file containing sample groups.\n",
    "    Returns:\n",
    "        tuple: Lists of training, validation, and test sample names.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        groups_df = pd.read_excel(excel_file_path)\n",
    "        train_samples = groups_df['Train Samples'].dropna().tolist()\n",
    "        val_samples = groups_df['Validation Samples'].dropna().tolist()\n",
    "        test_samples = groups_df['Test Samples'].dropna().tolist()\n",
    "        return train_samples, val_samples, test_samples\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Sample groups file not found at {excel_file_path}\")\n",
    "        return [], [], []\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "        return [], [], []\n",
    "\n",
    "# Load sample groups\n",
    "train_samples, val_samples, test_samples = load_sample_groups(EXCEL_FILE_PATH)\n",
    "\n",
    "def categorize_images(image_data, train_samples, val_samples, test_samples):\n",
    "    \"\"\"\n",
    "    Categorizes images into training, validation, and test sets based on sample names.\n",
    "\n",
    "    Parameters:\n",
    "    image_data (list): List of dictionaries containing image metadata.\n",
    "    train_samples (list): List of sample names designated for training.\n",
    "    val_samples (list): List of sample names designated for validation.\n",
    "    test_samples (list): List of sample names designated for testing.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Lists of categorized image data for training, validation, and testing.\n",
    "    \"\"\"\n",
    "    train_set, val_set, test_set = [], [], []\n",
    "    for data in image_data:\n",
    "        sample_name = \" \".join(data['name'].split('_')[:2])  # Extract sample ID\n",
    "        if sample_name in train_samples:\n",
    "            train_set.append(data)\n",
    "        elif sample_name in val_samples:\n",
    "            val_set.append(data)\n",
    "        elif sample_name in test_samples:\n",
    "            test_set.append(data)\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "# Categorize images into train, validation, and test sets\n",
    "train_set, val_set, test_set = categorize_images(image_dicts, train_samples, val_samples, test_samples)\n",
    "\n",
    "# Shuffle datasets\n",
    "train_set = shuffle(train_set, random_state=42)\n",
    "val_set = shuffle(val_set, random_state=42)\n",
    "test_set = shuffle(test_set, random_state=42)\n",
    "\n",
    "def get_base_name(name):\n",
    "    \"\"\"\n",
    "    Extracts the base name from an image filename before the \"DOCI_n\" part.\n",
    "    Parameters:\n",
    "        name (str): The image filename.\n",
    "    Returns:\n",
    "        str: The base name extracted from the filename.\n",
    "    \"\"\"\n",
    "    return name.split('_DOCI')[0]\n",
    "\n",
    "def get_doci_number(name):\n",
    "    \"\"\"\n",
    "    Extracts the DOCI number (n) from an image filename.\n",
    "    Parameters:\n",
    "        name (str): The image filename.\n",
    "    Returns:\n",
    "        int: The extracted DOCI number, or -1 if not found.\n",
    "    \"\"\"\n",
    "    \n",
    "    match = re.search(r'_DOCI_(\\d+)', name)\n",
    "    return int(match.group(1)) if match else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a4636-7f24-4b7f-8852-cf87f1370e20",
   "metadata": {},
   "source": [
    "# Averaging after PCA\n",
    "\n",
    "Comparing normal all tissue (from tissue_cutout) with cancer regions of cancer samples (from mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be19ab0-2ff8-4cc4-9774-3c8cfb56b1cb",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bada8f2-48de-4524-826b-f69a66bcdd09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to group images by sample and ensure correct order\n",
    "def group_images_by_sample(image_set):\n",
    "    \"\"\"\n",
    "    Groups images by their sample name and ensures correct order.\n",
    "    Parameters:\n",
    "        image_set (list): A list of dictionaries, each representing an image with a 'name' key.\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are sample names and values are lists of image dictionaries sorted by order.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Grouping images by sample...\")\n",
    "    grouped_samples = defaultdict(list)\n",
    "    for img_dict in image_set:\n",
    "        base_name = get_base_name(img_dict['name'])\n",
    "        if base_name.replace(\"_\", \" \") not in test_samples:\n",
    "            grouped_samples[base_name].append(img_dict)\n",
    "    \n",
    "    # Sort images within each sample\n",
    "    for key in grouped_samples:\n",
    "        grouped_samples[key] = sorted(grouped_samples[key], key=lambda x: get_doci_number(x['name']))\n",
    "    \n",
    "    print(f\"Grouped {len(grouped_samples)} samples.\")\n",
    "    return grouped_samples\n",
    "\n",
    "# Function to create a mask for non-black pixels in image_cutoff\n",
    "def create_tissue_mask(image_cutoff, black_tolerance=5):\n",
    "    \"\"\"\n",
    "    Creates a binary mask for non-black pixels in the given image.\n",
    "    Parameters:\n",
    "        image_cutoff (numpy array): The input image.\n",
    "        black_tolerance (int): Threshold for defining black pixels.\n",
    "    Returns:\n",
    "        numpy array: A binary mask where non-black pixels are marked as 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    img_array = np.array(image_cutoff)\n",
    "    tissue_mask = (img_array > black_tolerance).astype(np.uint8)\n",
    "    return tissue_mask\n",
    "\n",
    "# Aggregate pixel values into a 23-length vector per pixel location\n",
    "def aggregate_pixel_vectors(sample_images):\n",
    "    \"\"\"\n",
    "    Aggregates pixel values from a set of sample images into 23-length vectors.\n",
    "    Parameters:\n",
    "        sample_images (list): A list of image dictionaries containing grayscale image data.\n",
    "    Returns:\n",
    "        numpy array: An array where each row represents a 23-length pixel vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Aggregating pixel vectors...\")\n",
    "    img_shape = np.array(sample_images[0]['grayscale']).shape\n",
    "    height, width = img_shape\n",
    "    pixel_vectors = []\n",
    "\n",
    "    # Create masks: one for Normal samples and one common for all images in the sample\n",
    "    normal_mask = None\n",
    "    img_arrays = np.array([np.array(img_dict['grayscale']) for img_dict in sample_images])\n",
    "\n",
    "    # Pre-compute mask for non-Normal samples outside the pixel loops\n",
    "    mask = np.array(sample_images[0]['mask']).astype(np.uint8) if sample_images[0]['tissue_type'] != 'Normal' else None\n",
    "\n",
    "    # Iterate through each pixel location\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pixel_values = []\n",
    "\n",
    "            if sample_images[0]['tissue_type'] == 'Normal':\n",
    "                if normal_mask is None:\n",
    "                    img_cutoff = np.array(sample_images[0]['image_grayscale_cutoff'])\n",
    "                    normal_mask = create_tissue_mask(img_cutoff)\n",
    "                    print(\"Created tissue mask for Normal sample.\")\n",
    "\n",
    "                if normal_mask[y, x] == 1:\n",
    "                    pixel_values = img_arrays[:, y, x]\n",
    "            else:\n",
    "                if mask[y, x] > 0:\n",
    "                    pixel_values = img_arrays[:, y, x]\n",
    "\n",
    "            # Only consider pixel locations that have valid values\n",
    "            if len(pixel_values) == 23:\n",
    "                pixel_vectors.append(pixel_values)\n",
    "\n",
    "    print(f\"Aggregated pixel vectors: {len(pixel_vectors)} valid pixels found.\")\n",
    "    return np.array(pixel_vectors)\n",
    "\n",
    "def prepare_data_for_pca(grouped_samples):\n",
    "    \"\"\"\n",
    "    Prepares pixel vector data for PCA by aggregating values and assigning labels.\n",
    "    Parameters:\n",
    "        grouped_samples (dict): Dictionary of grouped images by sample.\n",
    "    Returns:\n",
    "        tuple: (combined pixel vectors, sample labels, tissue types).\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Preparing data for PCA...\")\n",
    "    all_pixel_vectors = []\n",
    "    sample_labels = []\n",
    "    tissue_types = []\n",
    "\n",
    "    for sample_name, sample_images in grouped_samples.items():\n",
    "        aggregated_pixel_vectors = aggregate_pixel_vectors(sample_images)\n",
    "        if aggregated_pixel_vectors.size > 0:\n",
    "            all_pixel_vectors.append(aggregated_pixel_vectors)\n",
    "\n",
    "            # Extend sample labels and tissue types for the valid pixel vectors only\n",
    "            num_valid_vectors = aggregated_pixel_vectors.shape[0]\n",
    "            sample_labels.extend([sample_name] * num_valid_vectors)\n",
    "            tissue_types.extend([sample_images[0]['tissue_type']] * num_valid_vectors)\n",
    "\n",
    "    # Concatenate all pixel vectors for PCA\n",
    "    if all_pixel_vectors:\n",
    "        combined_samples = np.concatenate(all_pixel_vectors, axis=0)\n",
    "        print(f\"Combined pixel vectors for PCA with shape: {combined_samples.shape}.\")\n",
    "    else:\n",
    "        combined_samples = np.array([])\n",
    "\n",
    "    # Ensure labels and tissue types match the number of valid samples\n",
    "    assert len(sample_labels) == combined_samples.shape[0], \"Mismatch between labels and PCA input.\"\n",
    "    assert len(tissue_types) == combined_samples.shape[0], \"Mismatch between tissue types and PCA input.\"\n",
    "\n",
    "    print(f\"Prepared data for {len(all_pixel_vectors)} samples.\")\n",
    "    return combined_samples, sample_labels, tissue_types\n",
    "\n",
    "\n",
    "# Perform PCA on the aggregated samples\n",
    "def perform_pca_on_samples(aggregated_samples, n_components=2):\n",
    "    \"\"\"\n",
    "    Performs PCA on aggregated sample pixel data.\n",
    "    Parameters:\n",
    "        aggregated_samples (numpy array): The aggregated pixel vectors.\n",
    "        n_components (int): Number of PCA components to retain.\n",
    "    Returns:\n",
    "        numpy array: PCA transformed results.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Performing PCA...\")\n",
    "    if aggregated_samples.size == 0:\n",
    "        print(\"No valid samples to perform PCA.\")\n",
    "        return np.array([])\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(aggregated_samples)\n",
    "    print(\"PCA completed.\")\n",
    "    return pca_result\n",
    "\n",
    "# Average PCA results for each sample (element-wise)\n",
    "def average_pca_per_sample(pca_result, sample_labels, tissue_types):\n",
    "    \"\"\"\n",
    "    Computes the average PCA values for each unique sample.\n",
    "    Parameters:\n",
    "        pca_result (numpy array): The PCA transformed data.\n",
    "        sample_labels (list): Labels indicating which sample each PCA result belongs to.\n",
    "        tissue_types (list): Corresponding tissue type for each sample.\n",
    "    Returns:\n",
    "        tuple: (numpy array of averaged PCA values, list of corresponding tissue types).\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Averaging PCA results per sample...\")\n",
    "    averaged_pca = []\n",
    "    averaged_tissue_types = []\n",
    "    unique_samples = set(sample_labels)\n",
    "\n",
    "    for sample in unique_samples:\n",
    "        indices = [i for i, label in enumerate(sample_labels) if label == sample]\n",
    "        sample_pca = pca_result[indices]\n",
    "\n",
    "        if len(sample_pca) > 0:\n",
    "            averaged_pca.append(np.mean(sample_pca, axis=0))\n",
    "            averaged_tissue_types.append(tissue_types[indices[0]])\n",
    "\n",
    "    print(f\"Averaged PCA results for {len(averaged_pca)} samples.\")\n",
    "    return np.array(averaged_pca), averaged_tissue_types\n",
    "    \n",
    "\n",
    "def plot_pca_results(pca_result, tissue_types):\n",
    "    \"\"\"\n",
    "    Plots the PCA results with color-coded tissue types.\n",
    "    Parameters:\n",
    "        pca_result (numpy array): PCA transformed data.\n",
    "        tissue_types (list): List of tissue type labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pca_result.size == 0:\n",
    "        print(\"No PCA results to plot.\")\n",
    "        return\n",
    "\n",
    "    print(\"Plotting PCA results...\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Color map for tissue types\n",
    "    tissue_type_colors = {'Normal': 'blue', 'Follicular': 'orange', 'Papillary': 'green', 'Anaplastic': 'red'}\n",
    "    colors = [tissue_type_colors[tissue] for tissue in tissue_types]\n",
    "\n",
    "    # Average PCA coordinates for samples and plot\n",
    "    averaged_pca, averaged_tissue_types = average_pca_per_sample(pca_result, sample_labels, tissue_types)\n",
    "    scatter = plt.scatter(averaged_pca[:, 0], averaged_pca[:, 1], c=[tissue_type_colors[tissue] for tissue in averaged_tissue_types], marker='X')\n",
    "\n",
    "    # Create legend\n",
    "    handles = [plt.Line2D([0], [0], marker='X', color='w', label=tissue, \n",
    "                           markerfacecolor=color, markersize=10) for tissue, color in tissue_type_colors.items()]\n",
    "    plt.legend(handles=handles, title=\"Tissue Type\")\n",
    "\n",
    "    plt.title(\"PCA of Samples Based on Aggregated Pixel Values\")\n",
    "    plt.xlabel(\"PC 1\")\n",
    "    plt.ylabel(\"PC 2\")\n",
    "    plt.show()\n",
    "    print(\"PCA results plotted.\")\n",
    "\n",
    "\n",
    "# Main execution flow\n",
    "file_path = 'data/image_dicts_256_wgrayscale_andcutoffs.pkl'\n",
    "image_dicts = load_image_dicts(file_path)\n",
    "\n",
    "# Group images by sample\n",
    "grouped_samples = group_images_by_sample(image_dicts)\n",
    "\n",
    "# Prepare the data for PCA\n",
    "all_samples, sample_labels, tissue_types = prepare_data_for_pca(grouped_samples)\n",
    "\n",
    "\n",
    "def plot_raw_pca_results(pca_result, tissue_types, sample_labels):\n",
    "    \"\"\"\n",
    "    Plots raw PCA results for individual pixel locations.\n",
    "    Parameters:\n",
    "        pca_result (numpy array): PCA transformed data.\n",
    "        tissue_types (list): List of tissue type labels.\n",
    "        sample_labels (list): List of sample labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pca_result.size == 0:\n",
    "        print(\"No PCA results to plot.\")\n",
    "        return\n",
    "\n",
    "    print(\"Plotting raw PCA results (per pixel)...\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Color map for tissue types\n",
    "    tissue_type_colors = {'Normal': 'blue', 'Follicular': 'orange', 'Papillary': 'green', 'Anaplastic': 'red'}\n",
    "    colors = [tissue_type_colors[tissue] for tissue in tissue_types]\n",
    "\n",
    "    scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], c=colors, s=1, alpha=0.5)\n",
    "\n",
    "    # Create legend\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', label=tissue, \n",
    "                           markerfacecolor=color, markersize=10) for tissue, color in tissue_type_colors.items()]\n",
    "    plt.legend(handles=handles, title=\"Tissue Type\", loc='upper right')\n",
    "\n",
    "    plt.title(\"Raw PCA of Pixel Values\")\n",
    "    plt.xlabel(\"PC 1\")\n",
    "    plt.ylabel(\"PC 2\")\n",
    "    plt.show()\n",
    "    print(\"Raw PCA results plotted.\")\n",
    "\n",
    "# Perform PCA\n",
    "pca_result = perform_pca_on_samples(all_samples)\n",
    "\n",
    "# Plot raw PCA results for all pixel locations\n",
    "plot_raw_pca_results(pca_result, tissue_types, sample_labels)\n",
    "\n",
    "# Plot averaged PCA results\n",
    "plot_pca_results(pca_result, tissue_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dac159-ef4a-4270-b112-b2e0a673f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the aggregated samples and compute explained variance\n",
    "def perform_pca_with_variance(aggregated_samples, n_components=10):\n",
    "    \"\"\"\n",
    "    Performs Principal Component Analysis (PCA) on the given aggregated samples \n",
    "    and computes the explained variance ratio for each principal component.\n",
    "    Parameters:\n",
    "        aggregated_samples (numpy.ndarray): The dataset to perform PCA on, with samples as rows.\n",
    "        n_components (int, optional): The number of principal components to compute. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "        - numpy.ndarray: Transformed data after applying PCA.\n",
    "        - list: Explained variance ratio for each principal component.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Performing PCA with variance computation...\")\n",
    "    if aggregated_samples.size == 0:\n",
    "        print(\"No valid samples to perform PCA.\")\n",
    "        return np.array([]), []\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(aggregated_samples)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"PCA completed. Explained variance by components: {explained_variance}\")\n",
    "    return pca_result, explained_variance\n",
    "\n",
    "\n",
    "# Plot explained variance ratio (sideways with PC 1 at the top)\n",
    "def plot_explained_variance(explained_variance):\n",
    "    \"\"\"\n",
    "    Plots the explained variance ratio of the principal components as a horizontal bar chart.\n",
    "    Parameters:\n",
    "        explained_variance (list or numpy.ndarray): The explained variance ratio for each principal component.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Plotting explained variance ratio...\")\n",
    "    plt.figure(figsize=(8, 12))\n",
    "    \n",
    "    components = range(1, len(explained_variance) + 1)\n",
    "    plt.barh(\n",
    "        components, \n",
    "        explained_variance, \n",
    "        color='skyblue'  # Set bar color to sky blue\n",
    "    )\n",
    "    \n",
    "    # Add title, labels, and ticks with increased font size\n",
    "    plt.title(\"Explained Variance by Principal Components\", fontsize=20)\n",
    "    plt.ylabel(\"Principal Components\", fontsize=19)\n",
    "    plt.xlabel(\"Explained Variance Ratio\", fontsize=19)\n",
    "    plt.yticks(components, labels=[f'PC {i}' for i in components], fontsize=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    \n",
    "    # Reverse the order of the y-axis to make PC 1 appear at the top\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Customize grid lines for better visibility\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Explained variance ratio plotted.\")\n",
    "\n",
    "\n",
    "# Perform PCA and compute explained variance\n",
    "pca_result, explained_variance = perform_pca_with_variance(all_samples)\n",
    "\n",
    "# Plot explained variance\n",
    "if explained_variance.size > 0:\n",
    "    plot_explained_variance(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b7d81-8024-4c2f-9380-15b4a6f0c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot absolute PCA loadings for PC1 and PC2 as stacked bars\n",
    "def plot_absolute_pca_loadings(pca):\n",
    "    \"\"\"\n",
    "    Plots the absolute PCA loadings for the first two principal components (PC1 and PC2)\n",
    "    as a stacked bar chart.\n",
    "\n",
    "    Parameters:\n",
    "        pca (sklearn.decomposition.PCA): The PCA object after fitting the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Plotting absolute PCA loadings for PC1 and PC2 (stacked)...\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x_ticks = [f\"Filter {i+1}\" for i in range(pca.components_.shape[1])]\n",
    "\n",
    "    # Absolute loadings for PC1 and PC2\n",
    "    pc1_loadings = np.abs(pca.components_[0])\n",
    "    pc2_loadings = np.abs(pca.components_[1])\n",
    "\n",
    "    # Plot stacked bars\n",
    "    plt.bar(x_ticks, pc1_loadings, alpha=0.7, label='PC1')\n",
    "    plt.bar(x_ticks, pc2_loadings, alpha=0.7, label='PC2', bottom=pc1_loadings)\n",
    "\n",
    "    plt.title(\"Absolute PCA Loadings for PC1 and PC2\")\n",
    "    plt.xlabel(\"Filters\")\n",
    "    plt.ylabel(\"Absolute Loadings\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Stacked absolute PCA loadings plotted.\")\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(all_samples)\n",
    "\n",
    "# Plot stacked absolute PCA loadings\n",
    "plot_absolute_pca_loadings(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f91f4-a6eb-4164-9ad9-aa12ed092813",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels_unique = set(sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266c673-a315-4353-9025-779a7a61290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_images_by_sample2(image_set):\n",
    "    \"\"\"\n",
    "    Groups images by their corresponding sample based on their base names.\n",
    "    Parameters:\n",
    "        image_set (list of dict): A list of image dictionaries containing metadata, including 'name'.\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are base sample names, and values are lists of image dictionaries\n",
    "          corresponding to that sample.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Grouping images by sample...\")\n",
    "    grouped_samples = defaultdict(list)\n",
    "    for img_dict in image_set:\n",
    "        base_name = get_base_name(img_dict['name'])\n",
    "        if base_name.replace(\"_\", \" \") in test_samples:\n",
    "            grouped_samples[base_name].append(img_dict)\n",
    "    \n",
    "    # Sort images within each sample\n",
    "    for key in grouped_samples:\n",
    "        grouped_samples[key] = sorted(grouped_samples[key], key=lambda x: get_doci_number(x['name']))\n",
    "    \n",
    "    print(f\"Grouped {len(grouped_samples)} samples.\")\n",
    "    return grouped_samples\n",
    "\n",
    "\n",
    "# Main execution flow\n",
    "file_path = 'data\\\\image_dicts_256_wgrayscale_andcutoffs.pkl'\n",
    "image_dicts = load_image_dicts(file_path)\n",
    "grouped_samples1 = group_images_by_sample2(image_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f069299-3e4b-45c0-ad53-d35f0797c770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0257d3ff-725f-46c5-a724-4f00b2733b8d",
   "metadata": {},
   "source": [
    "# Plotting Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650445a-898b-480f-9ccd-154982d0cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_with_boundaries_and_test(pca_result, tissue_types, grouped_test_samples, n_neighbors=):\n",
    "    \"\"\"\n",
    "    Plots the PCA results with decision boundaries and test samples using a k-Nearest Neighbors (k-NN) classifier.\n",
    "    \n",
    "    This function visualizes the separation of tissue types in PCA space by:\n",
    "    - Training a k-NN classifier on the PCA-transformed training data (excluding 'Anaplastic' tissue type).\n",
    "    - Plotting decision boundaries based on the trained k-NN model.\n",
    "    - Displaying training samples with different markers and colors based on tissue type.\n",
    "    - Overlaying test samples and their corresponding classifications.\n",
    "    - Calculating and printing training and test accuracy metrics.\n",
    "\n",
    "    Parameters:\n",
    "        pca_result (numpy.ndarray): The PCA-transformed feature set.\n",
    "        tissue_types (list): A list of tissue type labels corresponding to the PCA-transformed training samples.\n",
    "        grouped_test_samples (dict): A dictionary containing test samples grouped by their base sample name.\n",
    "        n_neighbors (int): The number of neighbors to use for k-NN classification.\n",
    "    \"\"\"\"\n",
    "    \n",
    "    print(\"Plotting PCA results with decision boundaries and test samples...\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    # Color map for tissue types\n",
    "    tissue_type_colors = {'Normal': 'blue', 'Follicular': 'orange', 'Papillary': 'green', 'Anaplastic': 'red'}\n",
    "\n",
    "    # Average PCA coordinates for training samples\n",
    "    averaged_pca_train, averaged_tissue_types_train = average_pca_per_sample(pca_result, sample_labels, tissue_types)\n",
    "\n",
    "    # Exclude 'Anaplastic' points from the training data\n",
    "    non_anaplastic_indices = [i for i, tissue in enumerate(averaged_tissue_types_train) if tissue != 'Anaplastic']\n",
    "    X_train = np.array([averaged_pca_train[i] for i in non_anaplastic_indices])  # Features\n",
    "    y_train = np.array([list(tissue_type_colors.keys()).index(tissue) for i, tissue in enumerate(averaged_tissue_types_train) if tissue != 'Anaplastic'])  # Labels\n",
    "\n",
    "    # Train k-NN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Adjust the plot limits to include \"Anaplastic\" samples\n",
    "    anaplastic_points = np.array([averaged_pca_train[i] for i, tissue in enumerate(averaged_tissue_types_train) if tissue == 'Anaplastic'])\n",
    "    x_min = min(X_train[:, 0].min(), anaplastic_points[:, 0].min()) - 10\n",
    "    x_max = max(X_train[:, 0].max(), anaplastic_points[:, 0].max()) + 10\n",
    "    y_min = min(X_train[:, 1].min(), anaplastic_points[:, 1].min()) - 10\n",
    "    y_max = max(X_train[:, 1].max(), anaplastic_points[:, 1].max()) + 10\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300), np.linspace(y_min, y_max, 300))\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    Z_cleaned = preprocess_and_remove_islands_v5(Z, size_threshold=400)\n",
    "\n",
    "    # Generate a colormap dynamically for the unique areas in Z_cleaned\n",
    "    unique_areas = np.unique(Z_cleaned)\n",
    "    cmap = ListedColormap([tissue_type_colors[t] for t in tissue_type_colors.keys() if t != 'Anaplastic'])\n",
    "    \n",
    "    # Map unique areas to sequential indices for coloring\n",
    "    area_to_color = {area: idx for idx, area in enumerate(unique_areas)}\n",
    "    Z_mapped = np.vectorize(area_to_color.get)(Z_cleaned)\n",
    "    \n",
    "    # Plot decision boundaries\n",
    "    plt.contourf(xx, yy, Z_mapped, alpha=0.3, cmap=cmap)\n",
    "    \n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1],\n",
    "                c=[tissue_type_colors[tissue] for i, tissue in enumerate(averaged_tissue_types_train) if tissue != 'Anaplastic'], \n",
    "                marker='X', label='Training Samples')\n",
    "    \n",
    "    \n",
    "    # Plot \"Anaplastic\" training samples\n",
    "    if len(anaplastic_points) > 0:\n",
    "        plt.scatter(anaplastic_points[:, 0], anaplastic_points[:, 1],\n",
    "                    c='red', marker='X', label='Training: Anaplastic')\n",
    "    \n",
    "    # Prepare test samples\n",
    "    test_samples, test_labels, test_tissue_types = prepare_data_for_pca(grouped_test_samples)\n",
    "    test_pca = perform_pca_on_samples(test_samples, n_components=2)\n",
    "    \n",
    "    # Average PCA coordinates for test samples\n",
    "    averaged_pca_test, averaged_tissue_types_test = average_pca_per_sample(test_pca, test_labels, test_tissue_types)\n",
    "    \n",
    "    # Combine training and test samples for prediction printing\n",
    "    combined_samples = np.vstack((averaged_pca_train, averaged_pca_test))\n",
    "    combined_tissue_types = averaged_tissue_types_train + averaged_tissue_types_test\n",
    "    combined_names = list(sample_labels_unique) + list(set(test_labels))\n",
    "    \n",
    "    \n",
    "    # Predict labels for combined samples\n",
    "    combined_predictions = knn.predict(np.array(combined_samples))\n",
    "    combined_predicted_tissue_types = [list(tissue_type_colors.keys())[pred] for pred in combined_predictions]\n",
    "    \n",
    "    prediction_df = pd.DataFrame({\n",
    "        'Sample Name': combined_names,\n",
    "        'True Tissue Type': combined_tissue_types,\n",
    "        'Predicted Tissue Type': combined_predicted_tissue_types\n",
    "    })\n",
    "    \n",
    "    print(\"Prediction Results:\")\n",
    "    print(prediction_df)\n",
    "    \n",
    "    # Plot test samples\n",
    "    plt.scatter(np.array(averaged_pca_test)[:, 0], np.array(averaged_pca_test)[:, 1],\n",
    "                c=[tissue_type_colors[tissue] for tissue in averaged_tissue_types_test], \n",
    "                marker='o', edgecolor='k', label='Test Samples')\n",
    "    \n",
    "    # Create legend\n",
    "    handles = [\n",
    "        plt.Line2D([0], [0], marker='X', color='w', label=f'Training: {tissue}',\n",
    "                   markerfacecolor=color, markersize=10, markeredgecolor='k')\n",
    "        for tissue, color in tissue_type_colors.items()\n",
    "    ] + [\n",
    "        plt.Line2D([0], [0], marker='o', color='k', label='Test Samples', markerfacecolor='none', markersize=10)\n",
    "    ]\n",
    "    plt.legend(handles=handles, title=\"Tissue Type\")\n",
    "    \n",
    "    plt.title(\"PCA of Samples with Decision Boundaries (Training and Test)\")\n",
    "    plt.xlabel(\"PC 1\")\n",
    "    plt.ylabel(\"PC 2\")\n",
    "    plt.show()\n",
    "    print(\"Decision boundaries plotted with test samples.\")\n",
    "    \n",
    "    # Calculate accuracy for the training set\n",
    "    y_pred_train = knn.predict(np.array(averaged_pca_train))\n",
    "    \n",
    "    anaplastic_indices_train = [i for i, tissue in enumerate(averaged_tissue_types_train) if tissue == 'Anaplastic']\n",
    "    success_count_train_anaplastic = sum((y_pred_train[i] != list(tissue_type_colors.keys()).index('Normal')) for i in anaplastic_indices_train)\n",
    "    total_anaplastic_train = len(anaplastic_indices_train)\n",
    "    \n",
    "    # Non-Anaplastic accuracy for training\n",
    "    y_train_non_anaplastic = np.array([list(tissue_type_colors.keys()).index(tissue) for i, tissue in enumerate(averaged_tissue_types_train) if tissue != 'Anaplastic'])\n",
    "    y_pred_train_non_anaplastic = [y_pred_train[i] for i in non_anaplastic_indices]\n",
    "    accuracy_train_non_anaplastic = accuracy_score(y_train_non_anaplastic, y_pred_train_non_anaplastic)\n",
    "    \n",
    "    # Combine non-Anaplastic accuracy with Anaplastic success rate\n",
    "    if total_anaplastic_train > 0:\n",
    "        anaplastic_train_success_rate = success_count_train_anaplastic / total_anaplastic_train\n",
    "        accuracy_train_inclusive = (accuracy_train_non_anaplastic * len(y_train_non_anaplastic) + success_count_train_anaplastic) / len(averaged_tissue_types_train)\n",
    "    else:\n",
    "        anaplastic_train_success_rate = 0\n",
    "        accuracy_train_inclusive = accuracy_train_non_anaplastic\n",
    "    \n",
    "    print(f\"Training Accuracy excluding 'Anaplastic': {accuracy_train_non_anaplastic:.2f}\")\n",
    "    print(f\"Training Accuracy including 'Anaplastic': {accuracy_train_inclusive:.2f}\")\n",
    "    print(f\"Training Success rate for 'Anaplastic' classification: {anaplastic_train_success_rate:.2f}\")\n",
    "    \n",
    "    \n",
    "    # Calculate accuracy for the test set\n",
    "    y_pred_test = knn.predict(np.array(averaged_pca_test))\n",
    "    \n",
    "    # Accuracy excluding \"Anaplastic\" in test set\n",
    "    non_anaplastic_test_indices = [i for i, tissue in enumerate(averaged_tissue_types_test) if tissue != 'Anaplastic']\n",
    "    y_test_non_anaplastic = np.array([list(tissue_type_colors.keys()).index(averaged_tissue_types_test[i]) for i in non_anaplastic_test_indices])\n",
    "    y_pred_test_non_anaplastic = [y_pred_test[i] for i in non_anaplastic_test_indices]\n",
    "    accuracy_test_non_anaplastic = accuracy_score(y_test_non_anaplastic, y_pred_test_non_anaplastic)\n",
    "    print(f\"Test Accuracy excluding 'Anaplastic': {accuracy_test_non_anaplastic:.2f}\")\n",
    "    \n",
    "    # Test Accuracy including \"Anaplastic\" (non-Normal success)\n",
    "    anaplastic_indices_test = [i for i, tissue in enumerate(averaged_tissue_types_test) if tissue == 'Anaplastic']\n",
    "    success_count_test_anaplastic = sum((y_pred_test[i] != list(tissue_type_colors.keys()).index('Normal')) for i in anaplastic_indices_test)\n",
    "    total_anaplastic_test = len(anaplastic_indices_test)\n",
    "    \n",
    "    # Non-Anaplastic accuracy for test set\n",
    "    if total_anaplastic_test > 0:\n",
    "        anaplastic_test_success_rate = success_count_test_anaplastic / total_anaplastic_test\n",
    "    else:\n",
    "        anaplastic_test_success_rate = 0\n",
    "    \n",
    "    # Combine non-Anaplastic accuracy with Anaplastic success rate\n",
    "    accuracy_test_inclusive = (\n",
    "        (accuracy_test_non_anaplastic * len(y_test_non_anaplastic) + success_count_test_anaplastic)\n",
    "        / len(averaged_tissue_types_test)\n",
    "    )\n",
    "    \n",
    "    print(f\"Test Accuracy including 'Anaplastic': {accuracy_test_inclusive:.2f}\")\n",
    "    print(f\"Test Success rate for 'Anaplastic' classification: {anaplastic_test_success_rate:.2f}\")\n",
    "\n",
    "\n",
    "def custom_label(decision_boundary):\n",
    "    \"\"\"\n",
    "    Custom labeling function using flood-fill to label connected regions.\n",
    "\n",
    "    Parameters:\n",
    "    - decision_boundary: 2D numpy array containing class predictions.\n",
    "\n",
    "    Returns:\n",
    "    - labeled_array: 2D numpy array where each connected region has a unique label.\n",
    "    - num_features: Number of connected regions.\n",
    "    \"\"\"\n",
    "    rows, cols = decision_boundary.shape\n",
    "    labeled_array = np.zeros_like(decision_boundary, dtype=int)\n",
    "    current_label = 1\n",
    "\n",
    "    def flood_fill(start_row, start_col, value):\n",
    "        queue = deque([(start_row, start_col)])\n",
    "        labeled_array[start_row, start_col] = current_label\n",
    "        while queue:\n",
    "            r, c = queue.popleft()\n",
    "            for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                nr, nc = r + dr, c + dc\n",
    "                if (\n",
    "                    0 <= nr < rows\n",
    "                    and 0 <= nc < cols\n",
    "                    and decision_boundary[nr, nc] == value\n",
    "                    and labeled_array[nr, nc] == 0\n",
    "                ):\n",
    "                    labeled_array[nr, nc] = current_label\n",
    "                    queue.append((nr, nc))\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if labeled_array[r, c] == 0:  # Unvisited pixel\n",
    "                flood_fill(r, c, decision_boundary[r, c])\n",
    "                current_label += 1\n",
    "\n",
    "    num_features = current_label - 1\n",
    "    return labeled_array, num_features\n",
    "\n",
    "\n",
    "def preprocess_and_remove_islands_v5(decision_boundary, size_threshold=300, distance=2, num_classes=3):\n",
    "    \"\"\"\n",
    "    Preprocesses the decision boundary to remove artifacts and eliminates small isolated regions (\"islands\").\n",
    "\n",
    "    Parameters:\n",
    "    - decision_boundary: 2D numpy array containing the class predictions for each grid point.\n",
    "    - size_threshold: The maximum size of regions to be considered as islands. Smaller regions will be removed.\n",
    "    - distance: The distance from the region boundary to consider for determining the majority class.\n",
    "    - num_classes: Number of discrete classes in the decision boundary.\n",
    "\n",
    "    Returns:\n",
    "    - A modified decision_boundary with islands removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Discretize the decision boundary into `num_classes` bins\n",
    "    decision_boundary_min = np.min(decision_boundary)\n",
    "    decision_boundary_max = np.max(decision_boundary)\n",
    "    bins = np.linspace(decision_boundary_min, decision_boundary_max, num_classes + 1)\n",
    "    decision_boundary = np.digitize(decision_boundary, bins) - 1\n",
    "\n",
    "    # Label contiguous regions in the decision boundary\n",
    "    labeled_regions, num_features = custom_label(decision_boundary)\n",
    "\n",
    "    # Copy the decision boundary for modifications\n",
    "    cleaned_boundary = decision_boundary.copy()\n",
    "\n",
    "    # Counter for removed islands\n",
    "    removed_islands_count = 0\n",
    "\n",
    "    # Analyze each region\n",
    "    for region_id in range(1, num_features + 1):\n",
    "        # Get the region mask\n",
    "        region_mask = (labeled_regions == region_id)\n",
    "        region_size = np.sum(region_mask)\n",
    "\n",
    "        # Check if the region is an island (below size threshold)\n",
    "        if region_size < size_threshold:\n",
    "            removed_islands_count += 1\n",
    "\n",
    "            # Expand the mask to determine the majority class\n",
    "            expanded_mask = binary_dilation(region_mask, iterations=distance)\n",
    "            surrounding_mask = expanded_mask & ~region_mask\n",
    "            surrounding_classes = decision_boundary[surrounding_mask]\n",
    "\n",
    "            if len(surrounding_classes) > 0:\n",
    "                majority_class = np.bincount(surrounding_classes).argmax()\n",
    "                cleaned_boundary[region_mask] = majority_class\n",
    "\n",
    "    return cleaned_boundary\n",
    "\n",
    "# Main execution flow\n",
    "file_path = 'C:\\\\Users\\\\Tyler\\\\CNN Project - Take 2\\\\CNN_Data_ver2\\\\image_dicts_256_wgrayscale_andcutoffs.pkl'\n",
    "image_dicts = load_image_dicts(file_path)\n",
    "grouped_samples1 = group_images_by_sample2(image_dicts)\n",
    "\n",
    "# Perform PCA with 2 components\n",
    "pca_result = perform_pca_on_samples(all_samples, n_components=2)\n",
    "\n",
    "# Plot boundaries with both training and test samples\n",
    "plot_pca_with_boundaries_and_test(pca_result, tissue_types, grouped_samples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab226e-54a4-417e-91da-6894bd6c9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_with_boundaries_and_test(pca_result, tissue_types, grouped_test_samples, n_neighbors=7):\n",
    "    \"\"\"\n",
    "    Plots PCA results with decision boundaries and test samples using a k-Nearest Neighbors (k-NN) classifier.\n",
    "\n",
    "    This function:\n",
    "    - Trains a k-NN classifier on PCA-transformed training data, excluding 'Anaplastic' samples.\n",
    "    - Plots decision boundaries using a cleaned classification grid.\n",
    "    - Displays training samples using different markers and colors based on tissue type.\n",
    "    - Computes and overlays test sample classifications.\n",
    "    - Remaps labels into three categories ('Normal', 'Follicular', and 'Papillary') for evaluation.\n",
    "    - Computes and visualizes confusion matrices for both training and test datasets.\n",
    "\n",
    "    Parameters:\n",
    "        pca_result (numpy.ndarray): The PCA-transformed feature set for training samples.\n",
    "        tissue_types (list): A list of tissue type labels corresponding to the training samples.\n",
    "        grouped_test_samples (dict): A dictionary containing test samples grouped by their base sample name.\n",
    "        n_neighbors (int, optional): The number of neighbors to use in the k-NN classifier. Default is 7.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Plotting PCA results with decision boundaries and test samples...\")\n",
    "    #plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Color map for tissue types\n",
    "    tissue_type_colors = {'Normal': 'blue', 'Follicular': 'orange', 'Papillary': 'green', 'Anaplastic': 'red'}\n",
    "\n",
    "    # Average PCA coordinates for training samples\n",
    "    averaged_pca_train, averaged_tissue_types_train = average_pca_per_sample(pca_result, sample_labels, tissue_types)\n",
    "\n",
    "    # Exclude 'Anaplastic' points from the training data\n",
    "    non_anaplastic_indices = [i for i, tissue in enumerate(averaged_tissue_types_train) if tissue != 'Anaplastic']\n",
    "    X_train = np.array([averaged_pca_train[i] for i in non_anaplastic_indices])  # Features\n",
    "    y_train = np.array([list(tissue_type_colors.keys()).index(tissue) for i, tissue in enumerate(averaged_tissue_types_train) if tissue != 'Anaplastic'])  # Labels\n",
    "\n",
    "    # Train k-NN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Adjust the plot limits to include \"Anaplastic\" samples\n",
    "    anaplastic_points = np.array([averaged_pca_train[i] for i, tissue in enumerate(averaged_tissue_types_train) if tissue == 'Anaplastic'])\n",
    "    x_min = min(X_train[:, 0].min(), anaplastic_points[:, 0].min()) - 10\n",
    "    x_max = max(X_train[:, 0].max(), anaplastic_points[:, 0].max()) + 10\n",
    "    y_min = min(X_train[:, 1].min(), anaplastic_points[:, 1].min()) - 10\n",
    "    y_max = max(X_train[:, 1].max(), anaplastic_points[:, 1].max()) + 10\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300), np.linspace(y_min, y_max, 300))\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    Z_cleaned = preprocess_and_remove_islands_v5(Z, size_threshold=400)\n",
    "\n",
    "    unique_areas = np.unique(Z_cleaned)\n",
    "    cmap = ListedColormap([tissue_type_colors[t] for t in tissue_type_colors.keys() if t != 'Anaplastic'])  # Use the first N colors from a colormap\n",
    "    \n",
    "    area_to_color = {area: idx for idx, area in enumerate(unique_areas)}\n",
    "    Z_mapped = np.vectorize(area_to_color.get)(Z_cleaned)  # Map Z_cleaned to the new color indices\n",
    "\n",
    "    # Prepare test samples\n",
    "    test_samples, test_labels, test_tissue_types = prepare_data_for_pca(grouped_test_samples)\n",
    "    test_pca = perform_pca_on_samples(test_samples, n_components=2)\n",
    "\n",
    "    # Average PCA coordinates for test samples\n",
    "    averaged_pca_test, averaged_tissue_types_test = average_pca_per_sample(test_pca, test_labels, test_tissue_types)\n",
    "\n",
    "    # Remap labels to 3 categories\n",
    "    # Adjusted remap_labels function\n",
    "    def remap_labels(y_true, y_pred, tissue_type_colors):\n",
    "        mapping = {'Normal': 0, 'Follicular': 1, 'Papillary': 2}\n",
    "        y_true_mapped = []\n",
    "        y_pred_mapped = []\n",
    "        \n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            true_label = list(tissue_type_colors.keys())[true]\n",
    "            pred_label = list(tissue_type_colors.keys())[pred]\n",
    "            \n",
    "            # Adjust true label for 'Anaplastic'\n",
    "            if true_label == 'Anaplastic':\n",
    "                if pred_label == 'Follicular':\n",
    "                    y_true_mapped.append(mapping['Follicular'])\n",
    "                elif pred_label == 'Papillary':\n",
    "                    y_true_mapped.append(mapping['Papillary'])\n",
    "                else:\n",
    "                    y_true_mapped.append(mapping['Anaplastic'])\n",
    "            else:\n",
    "                y_true_mapped.append(mapping[true_label])\n",
    "            \n",
    "            # Remap predicted label\n",
    "            if pred_label == 'Anaplastic':\n",
    "                y_pred_mapped.append(mapping['Anaplastic'])\n",
    "            else:\n",
    "                y_pred_mapped.append(mapping[pred_label])\n",
    "    \n",
    "        return y_true_mapped, y_pred_mapped\n",
    "\n",
    "    # Predict and remap labels for training set\n",
    "    y_pred_train = knn.predict(X_train)\n",
    "    y_true_train = y_train\n",
    "    y_true_train_mapped, y_pred_train_mapped = remap_labels(y_true_train, y_pred_train, tissue_type_colors)\n",
    "\n",
    "    # Predict and remap labels for test set\n",
    "    y_pred_test = knn.predict(np.array(averaged_pca_test))\n",
    "    y_true_test = np.array([list(tissue_type_colors.keys()).index(tissue) for tissue in averaged_tissue_types_test])\n",
    "    y_true_test_mapped, y_pred_test_mapped = remap_labels(y_true_test, y_pred_test, tissue_type_colors)\n",
    "\n",
    "    # Function to plot confusion matrix\n",
    "    def plot_confusion_matrix(y_true, y_pred, title):\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
    "        class_names = ['Normal', 'Follicular', 'Papillary']\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues', \n",
    "                    annot_kws={\"size\": 20})\n",
    "        plt.title(title, fontsize=16)\n",
    "        plt.xlabel('Predicted Label', fontsize=16)\n",
    "        plt.ylabel('True Label', fontsize=16)\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.show()\n",
    "        print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "\n",
    "    # Plot confusion matrix for training\n",
    "    print(\"\\nTraining Set Confusion Matrix:\")\n",
    "    plot_confusion_matrix(y_true_train_mapped, y_pred_train_mapped, \"Confusion Matrix - Training Set\")\n",
    "\n",
    "    # Plot confusion matrix for test\n",
    "    print(\"\\nTest Set Confusion Matrix:\")\n",
    "    plot_confusion_matrix(y_true_test_mapped, y_pred_test_mapped, \"Confusion Matrix - Test Set\")\n",
    "\n",
    "# Main execution flow\n",
    "file_path = 'C:\\\\Users\\\\Tyler\\\\CNN Project - Take 2\\\\CNN_Data_ver2\\\\image_dicts_256_wgrayscale_andcutoffs.pkl'\n",
    "image_dicts = load_image_dicts(file_path)\n",
    "grouped_samples1 = group_images_by_sample2(image_dicts)\n",
    "\n",
    "# Perform PCA with 2 components\n",
    "pca_result = perform_pca_on_samples(all_samples, n_components=2)\n",
    "\n",
    "# Plot boundaries with both training and test samples\n",
    "plot_pca_with_boundaries_and_test(pca_result, tissue_types, grouped_samples1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a992d-2ef0-45b5-83a2-ef838a2569ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a4a50d2-b3be-4d73-9212-ea32960a887a",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3553911-2134-4ba9-805d-eeb77ff6a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_knn(pca_result, tissue_types, grouped_test_samples, max_neighbors=10):\n",
    "    \"\"\"\n",
    "    Performs cross-validation to determine the optimal number of neighbors (k) for k-Nearest Neighbors (k-NN) classification.\n",
    "\n",
    "    This function:\n",
    "    - Computes the average PCA coordinates for training samples.\n",
    "    - Excludes 'Anaplastic' samples from training but evaluates their classification separately.\n",
    "    - Uses k-fold cross-validation (k=8) to evaluate training accuracy for different values of k.\n",
    "    - Includes a custom accuracy metric that factors in 'Anaplastic' classification success.\n",
    "    - Evaluates test set accuracy separately, considering 'Anaplastic' classification success.\n",
    "    - Plots accuracy results across different values of k.\n",
    "    - Returns the best value of k based on cross-validation results.\n",
    "\n",
    "    Parameters:\n",
    "        pca_result (numpy.ndarray): The PCA-transformed feature set for training samples.\n",
    "        tissue_types (list): A list of tissue type labels corresponding to the training samples.\n",
    "        grouped_test_samples (dict): A dictionary containing test samples grouped by their base sample name.\n",
    "        max_neighbors (int, optional): The maximum number of neighbors to consider in cross-validation. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        int: The optimal number of neighbors (k) based on training accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Performing cross-validation to optimize n_neighbors...\")\n",
    "    \n",
    "    # Color map for tissue types\n",
    "    tissue_type_colors = {'Normal': 'blue', 'Follicular': 'orange', 'Papillary': 'green', 'Anaplastic': 'red'}\n",
    "\n",
    "    # Average PCA coordinates for training samples\n",
    "    averaged_pca_train, averaged_tissue_types_train = average_pca_per_sample(pca_result, sample_labels, tissue_types)\n",
    "\n",
    "    # Prepare training data excluding \"Anaplastic\"\n",
    "    non_anaplastic_indices = [i for i, tissue in enumerate(averaged_tissue_types_train) if tissue != 'Anaplastic']\n",
    "    X_train = np.array([averaged_pca_train[i] for i in non_anaplastic_indices])  # Features\n",
    "    y_train = np.array([list(tissue_type_colors.keys()).index(tissue) for i, tissue in enumerate(averaged_tissue_types_train) if tissue != 'Anaplastic'])  # Labels\n",
    "\n",
    "    # Include \"Anaplastic\" samples for inclusive accuracy\n",
    "    anaplastic_indices_train = [i for i, tissue in enumerate(averaged_tissue_types_train) if tissue == 'Anaplastic']\n",
    "    X_train_anaplastic = np.array([averaged_pca_train[i] for i in anaplastic_indices_train])\n",
    "    \n",
    "    # Prepare test samples\n",
    "    test_samples, test_labels, test_tissue_types = prepare_data_for_pca(grouped_test_samples)\n",
    "    test_pca = perform_pca_on_samples(test_samples, n_components=2)\n",
    "    averaged_pca_test, averaged_tissue_types_test = average_pca_per_sample(test_pca, test_labels, test_tissue_types)\n",
    "    y_test = np.array([list(tissue_type_colors.keys()).index(tissue) for tissue in averaged_tissue_types_test])\n",
    "\n",
    "    # Cross-validation loop\n",
    "    kf = KFold(n_splits=8, shuffle=True, random_state=42)\n",
    "    train_accuracies = []\n",
    "    train_std_dev = []\n",
    "    test_accuracies = []\n",
    "    test_std_dev = []\n",
    "    neighbors_range = range(1, max_neighbors + 1)\n",
    "\n",
    "    for n_neighbors in neighbors_range:\n",
    "        print(f\"Evaluating n_neighbors={n_neighbors}...\")\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        \n",
    "        # Cross-validated training accuracy including \"Anaplastic\"\n",
    "        cv_train_accuracy = []\n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "            \n",
    "            knn.fit(X_train_fold, y_train_fold)\n",
    "            \n",
    "            # Predict on validation set\n",
    "            y_val_pred = knn.predict(X_val_fold)\n",
    "            \n",
    "            # Predict on \"Anaplastic\" in validation fold\n",
    "            y_pred_anaplastic = knn.predict(X_train_anaplastic)\n",
    "            success_anaplastic = sum((y_pred_anaplastic != list(tissue_type_colors.keys()).index('Normal')))\n",
    "            \n",
    "            # Combine non-Anaplastic accuracy with Anaplastic success\n",
    "            non_anaplastic_acc = accuracy_score(y_val_fold, y_val_pred)\n",
    "            combined_accuracy = (non_anaplastic_acc * len(y_val_fold) + success_anaplastic) / (len(y_val_fold) + len(X_train_anaplastic))\n",
    "            cv_train_accuracy.append(combined_accuracy)\n",
    "        \n",
    "        train_accuracies.append(np.mean(cv_train_accuracy))\n",
    "        train_std_dev.append(np.std(cv_train_accuracy))\n",
    "        \n",
    "        # Test set accuracy\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_test_pred = knn.predict(np.array(averaged_pca_test))\n",
    "        \n",
    "        # Test accuracy including \"Anaplastic\"\n",
    "        anaplastic_indices_test = [i for i, tissue in enumerate(averaged_tissue_types_test) if tissue == 'Anaplastic']\n",
    "        success_count_test_anaplastic = sum((y_test_pred[i] != list(tissue_type_colors.keys()).index('Normal')) for i in anaplastic_indices_test)\n",
    "        total_anaplastic_test = len(anaplastic_indices_test)\n",
    "        \n",
    "        if total_anaplastic_test > 0:\n",
    "            anaplastic_test_success_rate = success_count_test_anaplastic / total_anaplastic_test\n",
    "        else:\n",
    "            anaplastic_test_success_rate = 0\n",
    "        \n",
    "        accuracy_test_non_anaplastic = accuracy_score(\n",
    "            [y_test[i] for i in range(len(y_test)) if i not in anaplastic_indices_test],\n",
    "            [y_test_pred[i] for i in range(len(y_test_pred)) if i not in anaplastic_indices_test]\n",
    "        )\n",
    "        \n",
    "        combined_test_accuracy = (\n",
    "            (accuracy_test_non_anaplastic * (len(y_test) - total_anaplastic_test) + success_count_test_anaplastic) / len(y_test)\n",
    "        )\n",
    "        test_accuracies.append(combined_test_accuracy)\n",
    "        test_std_dev.append(0)  # Assuming no cross-validation for the test set\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    print(train_accuracies)\n",
    "    # Error bars for training accuracy\n",
    "    plt.errorbar(neighbors_range, train_accuracies, yerr=train_std_dev, \n",
    "                 label=\"Training Accuracy\", \n",
    "                 marker='o', capsize=5, ecolor='lightblue', elinewidth=1.5)\n",
    "    \n",
    "    # Error bars for test accuracy\n",
    "    plt.errorbar(neighbors_range, test_accuracies, yerr=test_std_dev, \n",
    "                 label=\"Test Accuracy\", \n",
    "                 marker='x', capsize=5, ecolor='orange', elinewidth=1.5)\n",
    "    \n",
    "    # Axis labels and title with increased font size\n",
    "    plt.xlabel(\"Number of Neighbors (K)\", fontsize=14)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "    plt.title(\"Cross-Validation for Optimizing K\", fontsize=16)\n",
    "    \n",
    "    # Legend with larger font size\n",
    "    plt.legend(fontsize=12)\n",
    "    \n",
    "    # Grid and larger tick labels\n",
    "    plt.grid()\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    # Report the best n_neighbors\n",
    "    best_n_neighbors = neighbors_range[np.argmax(train_accuracies)]\n",
    "    print(f\"Best n_neighbors based on training accuracy: {best_n_neighbors}\")\n",
    "    return best_n_neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1f1fa-33ab-48f4-8327-6e4c8e5652da",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_samples1 = group_images_by_sample2(image_dicts)\n",
    "best_n_neighbors = cross_validate_knn(pca_result, tissue_types, grouped_samples1, max_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f64881d-8d95-42ba-91d8-752a492a5556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
