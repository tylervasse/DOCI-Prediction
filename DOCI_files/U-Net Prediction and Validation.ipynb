{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6c65c-bea4-4674-b978-efc318aafa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Library ---\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Third-Party Libraries ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import (\n",
    "    label,\n",
    "    binary_dilation,\n",
    "    binary_erosion,\n",
    ")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    UpSampling2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    GlobalAveragePooling2D,\n",
    "    Reshape,\n",
    "    SpatialDropout2D,\n",
    "    Multiply,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from skimage.filters import threshold_otsu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a942c52-7a44-4766-a78c-5d4d4311f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Clean Imports (deduplicated and organized)\n",
    "# ===========================================\n",
    "\n",
    "# --------------------\n",
    "# Paths & source\n",
    "# --------------------\n",
    "BASE_PATH       = \"data\"\n",
    "FILENAME        = \"image_dicts_256_wgrayscale_andcutoffs.pkl\"\n",
    "FILE_PATH       = os.path.join(BASE_PATH, FILENAME)\n",
    "EXCEL_FILE_PATH = os.path.join(BASE_PATH, \"sample_groups.xlsx\")\n",
    "URL             = \"https://github.com/tylervasse/DOCI-Prediction/releases/download/v1.0/image_dicts_256_wgrayscale_andcutoffs.pkl\"\n",
    "\n",
    "# --------------------\n",
    "# IO helpers\n",
    "# --------------------\n",
    "def download_file(url, output_path):\n",
    "    \"\"\"\n",
    "    Downloads a file from a given URL if it does not already exist locally.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL pointing to the file to download.\n",
    "        output_path (str): Local path where the downloaded file should be saved.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints status messages indicating whether the file was downloaded\n",
    "            or already existed at the target path.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"File already exists at {output_path}\")\n",
    "        return\n",
    "    print(f\"Downloading to {output_path}...\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "def load_image_dicts(file_path):\n",
    "    \"\"\"\n",
    "    Loads a list of image dictionaries from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the pickle file containing serialized image data.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing image metadata and pixel data.\n",
    "              Returns an empty list if the file does not exist or loading fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_sample_groups(excel_file_path):\n",
    "    \"\"\"\n",
    "    Loads training, validation, and test sample group identifiers from an Excel file.\n",
    "\n",
    "    Args:\n",
    "        excel_file_path (str): Path to the Excel file specifying sample groups.\n",
    "                               Must contain the columns:\n",
    "                               'Train Samples', 'Validation Samples', 'Test Samples'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three lists:\n",
    "            - list of str: Training sample base names.\n",
    "            - list of str: Validation sample base names.\n",
    "            - list of str: Test sample base names.\n",
    "        Each list will be empty if the file is missing or cannot be parsed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(excel_file_path)\n",
    "        norm = lambda col: [s.strip().strip(\"'\") for s in df[col].dropna().tolist()]\n",
    "        return norm('Train Samples'), norm('Validation Samples'), norm('Test Samples')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Sample groups file not found at {excel_file_path}\")\n",
    "        return [], [], []\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel: {e}\")\n",
    "        return [], [], []\n",
    "\n",
    "# --------------------\n",
    "# Basic parsing utils\n",
    "# --------------------\n",
    "def get_base_name(name):\n",
    "    \"\"\"\n",
    "    Extracts the base sample name from a DOCI image filename.\n",
    "\n",
    "    Args:\n",
    "        name (str): Full image filename containing a suffix like '_DOCI_n'.\n",
    "\n",
    "    Returns:\n",
    "        str: The base name preceding '_DOCI_n', used to associate slices\n",
    "             belonging to the same specimen.\n",
    "    \"\"\"\n",
    "    return name.split('_DOCI')[0]\n",
    "\n",
    "def get_doci_number(name):\n",
    "    \"\"\"\n",
    "    Extracts the DOCI index number from an image filename.\n",
    "\n",
    "    Args:\n",
    "        name (str): Filename containing the pattern '_DOCI_<number>'.\n",
    "\n",
    "    Returns:\n",
    "        int: The extracted DOCI slice index. Returns -1 if no index is found.\n",
    "    \"\"\"\n",
    "    m = re.search(r'_DOCI_(\\d+)', name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "# --------------------\n",
    "# Split image dicts into splits by sample base name\n",
    "# --------------------\n",
    "def categorize_images(image_data, train_samples, val_samples, test_samples):\n",
    "    \"\"\"\n",
    "    Categorizes image dictionaries into training, validation, and test sets\n",
    "    based on their base sample names.\n",
    "\n",
    "    Args:\n",
    "        image_data (list of dict): List of image dictionaries containing at least\n",
    "                                   the key 'name'.\n",
    "        train_samples (list of str): Base names assigned to the training split.\n",
    "        val_samples (list of str): Base names assigned to the validation split.\n",
    "        test_samples (list of str): Base names assigned to the test split.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three lists:\n",
    "            - list of dict: Training image dictionaries.\n",
    "            - list of dict: Validation image dictionaries.\n",
    "            - list of dict: Test image dictionaries.\n",
    "    \"\"\"\n",
    "    train_set, val_set, test_set = [], [], []\n",
    "    for d in image_data:\n",
    "        base = \"_\".join(d['name'].split('_')[:2])  # e.g., 'SSW-23-12345_A1'\n",
    "        if base in train_samples:\n",
    "            train_set.append(d)\n",
    "        elif base in val_samples:\n",
    "            val_set.append(d)\n",
    "        elif base in test_samples:\n",
    "            test_set.append(d)\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "# --------------------\n",
    "# Voxelize per-sample (group by base name, sort by DOCI)\n",
    "# --------------------\n",
    "def samples_to_voxels(dataset):\n",
    "    \"\"\"\n",
    "    Groups individual DOCI images by specimen, sorts them by DOCI index,\n",
    "    and constructs voxel stacks across the depth dimension.\n",
    "\n",
    "    Args:\n",
    "        dataset (list of dict): List of image dictionaries containing keys:\n",
    "            - 'name' (str): Filename used to infer sample grouping.\n",
    "            - 'grayscale' (numpy.ndarray): 2D grayscale DOCI image.\n",
    "            - 'image_grayscale_cutoff' (numpy.ndarray): Cutoff-processed grayscale image.\n",
    "            - 'mask' (numpy.ndarray or None): Tumor mask, if available.\n",
    "            - 'tissue_type' (str): Annotated tissue label for the sample.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of voxelized sample dictionaries, each containing:\n",
    "            - 'name' (str): Base sample name.\n",
    "            - 'grayscale_voxel' (numpy.ndarray): Stacked grayscale images [H, W, D].\n",
    "            - 'grayscale_image_cutoff_voxel' (numpy.ndarray): Stacked cutoff images [H, W, D].\n",
    "            - 'tissue_type' (str): Tissue class for the sample.\n",
    "            - 'mask' (numpy.ndarray or None): First available mask across slices.\n",
    "    \"\"\"\n",
    "    grouped = defaultdict(lambda: {\n",
    "        'names': [], 'grayscale': [], 'image_grayscale_cutoff': [], 'mask': None, 'tissue_type': None\n",
    "    })\n",
    "\n",
    "    for d in dataset:\n",
    "        base = get_base_name(d['name'])\n",
    "        grouped[base]['names'].append(d['name'])\n",
    "        grouped[base]['grayscale'].append(d['grayscale'])\n",
    "        grouped[base]['image_grayscale_cutoff'].append(d['image_grayscale_cutoff'])\n",
    "        grouped[base]['tissue_type'] = d['tissue_type']\n",
    "        if grouped[base]['mask'] is None and d.get('mask') is not None:\n",
    "            grouped[base]['mask'] = d['mask']\n",
    "\n",
    "    voxelized = []\n",
    "    for base, g in grouped.items():\n",
    "        order = sorted(range(len(g['names'])), key=lambda i: get_doci_number(g['names'][i]))\n",
    "        gray     = [g['grayscale'][i] for i in order]\n",
    "        gray_cut = [g['image_grayscale_cutoff'][i] for i in order]\n",
    "        grayscale_voxel                 = np.stack(gray, axis=-1).astype(np.float32)     # [H,W,D]\n",
    "        grayscale_image_cutoff_voxel    = np.stack(gray_cut, axis=-1).astype(np.uint8)   # [H,W,D]\n",
    "\n",
    "        voxelized.append({\n",
    "            'name': base,\n",
    "            'grayscale_voxel': grayscale_voxel,\n",
    "            'grayscale_image_cutoff_voxel': grayscale_image_cutoff_voxel,\n",
    "            'tissue_type': g['tissue_type'],\n",
    "            'mask': g['mask']\n",
    "        })\n",
    "    return voxelized\n",
    "\n",
    "# ====================\n",
    "# Main flow\n",
    "# ====================\n",
    "# 1) Ensure data file\n",
    "download_file(URL, FILE_PATH)\n",
    "\n",
    "# 2) Load raw dicts\n",
    "image_dicts = load_image_dicts(FILE_PATH)\n",
    "\n",
    "# 3) Exclude specific samples by substring match in 'name'\n",
    "EXCLUDE_LIST = [\"SSW-23-14395_C2\", \"SSW-23-05363_A7\"]\n",
    "image_dicts = [d for d in image_dicts if not any(excl in d['name'] for excl in EXCLUDE_LIST)]\n",
    "\n",
    "# 4) Load sample groups from Excel\n",
    "train_samples, val_samples, test_samples = load_sample_groups(EXCEL_FILE_PATH)\n",
    "\n",
    "# 5) Assign to splits and shuffle at image level\n",
    "train_set, val_set, test_set = categorize_images(image_dicts, train_samples, val_samples, test_samples)\n",
    "train_set = shuffle(train_set, random_state=42)\n",
    "val_set   = shuffle(val_set,   random_state=42)\n",
    "test_set  = shuffle(test_set,  random_state=42)\n",
    "\n",
    "# 6) Voxelize per sample\n",
    "train_combined = samples_to_voxels(train_set)\n",
    "val_combined   = samples_to_voxels(val_set)\n",
    "test_combined  = samples_to_voxels(test_set)\n",
    "\n",
    "print(f\"Samples -> train: {len(train_combined)} | val: {len(val_combined)} | test: {len(test_combined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9e284-43af-4010-b169-6e8dcce8d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Load regional categorization results from Excel\n",
    "# --------------------\n",
    "excel_path = \"regional_categorization_results.xlsx\"\n",
    "df_cat = pd.read_excel(excel_path)\n",
    "\n",
    "# Build lookup: (split, name) -> predicted label\n",
    "cat_lookup = {\n",
    "    (str(row[\"split\"]), str(row[\"name\"])): str(row[\"predicted\"])\n",
    "    for _, row in df_cat.iterrows()\n",
    "}\n",
    "print(f\"[LOAD] Loaded {len(cat_lookup)} categorization entries from {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e42c59-37ae-4af7-be51-7913c0aaa4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- constants ---\n",
    "TISSUES3 = ['Normal', 'Follicular', 'Papillary']\n",
    "CLASS_TO_ID3 = {c: i for i, c in enumerate(TISSUES3)}\n",
    "TARGET_TUMOR = \"Papillary\"   # still used later when you want the TARGET-only map\n",
    "TARGET_ID = CLASS_TO_ID3[TARGET_TUMOR]\n",
    "\n",
    "# ---- Channel selection (0-based indices) ----\n",
    "# Define channels to REMOVE by index (1-based here for readability), then convert to 0-based indices.\n",
    "REMOVE_VOXEL_CHANNELS = [1, 2, 4, 7, 9, 11, 12, 14, 16, 17, 19]\n",
    "REMOVE_VOXEL_CHANNELS = [i - 1 for i in REMOVE_VOXEL_CHANNELS]\n",
    "\n",
    "# Optionally, explicitly define channels to KEEP (overrides REMOVE_* if not None)\n",
    "KEEP_VOXEL_CHANNELS = None \n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# Excel-based regional filtering + voxel-only augmentation\n",
    "# ===========================================\n",
    "# ---- CONFIG: which tumor class to filter out for this TARGET_TUMOR ----\n",
    "if TARGET_TUMOR == \"Papillary\":\n",
    "    FILTER_TUMOR = \"Follicular\"\n",
    "elif TARGET_TUMOR == \"Follicular\":\n",
    "    FILTER_TUMOR = \"Papillary\"\n",
    "else:\n",
    "    FILTER_TUMOR = \"\"\n",
    "\n",
    "FILTER_VALTEST = True\n",
    "assert FILTER_TUMOR in (\"Follicular\", \"Papillary\")\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# 1) Filtering using Excel-based predictions\n",
    "# ===========================================\n",
    "def filter_out_by_category_from_excel(samples, split_name, remove_class, lookup):\n",
    "    \"\"\"\n",
    "    Filters samples based on precomputed regional predictions stored in an\n",
    "    external Excel-derived lookup table.\n",
    "\n",
    "    For each sample, this function checks the predicted label from `lookup`\n",
    "    using the (split_name, sample_name) key. If the predicted label matches\n",
    "    `remove_class`, the sample is dropped; otherwise, it is retained. Samples\n",
    "    without an entry in the lookup are kept by default.\n",
    "\n",
    "    Args:\n",
    "        samples (list of dict): List of sample dictionaries (e.g., train_combined,\n",
    "            val_combined, test_combined), each containing at least a 'name' field.\n",
    "        split_name (str): Name of the dataset split, typically one of\n",
    "            {'train', 'val', 'test'}, used as part of the lookup key.\n",
    "        remove_class (str): Tumor class label to filter out, such as\n",
    "            'Follicular' or 'Papillary'.\n",
    "        lookup (dict): Dictionary mapping (split_name, sample_name) tuples to\n",
    "            predicted labels, e.g., {('train', 'SSW-23-12345_A1'): 'Papillary'}.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - list of dict: Samples retained after filtering (kept_samples).\n",
    "            - list of dict: Samples removed because their predicted label\n",
    "              matched `remove_class` (dropped_samples).\n",
    "    \"\"\"\n",
    "    kept, dropped = [], []\n",
    "    for d in samples:\n",
    "        name = str(d.get(\"name\", \"unknown_sample\"))\n",
    "        pred = lookup.get((split_name, name), None)\n",
    "\n",
    "        # If no prediction is found, keep by default\n",
    "        if pred is None:\n",
    "            kept.append(d)\n",
    "            continue\n",
    "\n",
    "        if pred == remove_class:\n",
    "            dropped.append(d)\n",
    "        else:\n",
    "            kept.append(d)\n",
    "    return kept, dropped\n",
    "\n",
    "\n",
    "# Use Excel lookup to build filtered splits\n",
    "train_px_kept, train_px_dropped = filter_out_by_category_from_excel(\n",
    "    train_combined, \"train\", FILTER_TUMOR, cat_lookup\n",
    ")\n",
    "\n",
    "if FILTER_VALTEST:\n",
    "    val_px_kept,  val_px_dropped  = filter_out_by_category_from_excel(\n",
    "        val_combined,  \"val\",  FILTER_TUMOR, cat_lookup\n",
    "    )\n",
    "    test_px_kept, test_px_dropped = filter_out_by_category_from_excel(\n",
    "        test_combined, \"test\", FILTER_TUMOR, cat_lookup\n",
    "    )\n",
    "    val_px  = val_px_kept\n",
    "    test_px = test_px_kept\n",
    "else:\n",
    "    val_px  = val_combined\n",
    "    test_px = test_combined\n",
    "\n",
    "print(\n",
    "    f\"[FILTER/EXCEL] kept: \"\n",
    "    f\"train={len(train_px_kept)} val={len(val_px)} test={len(test_px)}\"\n",
    ")\n",
    "print(\n",
    "    f\"[FILTER/EXCEL] dropped({FILTER_TUMOR}-pred): \"\n",
    "    f\"train={len(train_px_dropped)} \"\n",
    "    f\"val={len(val_px_dropped) if FILTER_VALTEST else 0} \"\n",
    "    f\"test={len(test_px_dropped) if FILTER_VALTEST else 0}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd792b5f-f8cf-4a57-afbe-b48a9308d8fb",
   "metadata": {},
   "source": [
    "# Augmentation for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be5b54-205e-4afd-8316-d635e97ef1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same regional params picked earlier\n",
    "REGIONAL_PARAMS = dict(\n",
    "    black_tol=5,\n",
    "    win=45,\n",
    "    stride=20,\n",
    "    frac_thresh=0.80,\n",
    "    min_tissue_px_per_win=30,\n",
    ")\n",
    "\n",
    "# ===========================================\n",
    "# 1) Channel selection helpers\n",
    "# ===========================================\n",
    "def _sanitize_indices(n_channels, keep, remove):\n",
    "    \"\"\"\n",
    "    Computes the final set of channel indices to retain, based on keep/remove\n",
    "    specifications and the total number of available channels.\n",
    "\n",
    "    Args:\n",
    "        n_channels (int): Total number of channels in the input array.\n",
    "        keep (list of int or None): Explicit list of channel indices to keep\n",
    "            (0-based). If not None, this overrides `remove`.\n",
    "        remove (list of int or None): List of channel indices to exclude\n",
    "            (0-based). Used only if `keep` is None.\n",
    "\n",
    "    Returns:\n",
    "        list of int: Sorted list of unique channel indices that should be\n",
    "        retained, restricted to the range [0, n_channels).\n",
    "    \"\"\"\n",
    "    if keep is not None:\n",
    "        keep = sorted(int(i) for i in keep if 0 <= int(i) < n_channels)\n",
    "        return keep\n",
    "    # build keep from remove\n",
    "    remove = set(int(i) for i in (remove or []) if 0 <= int(i) < n_channels)\n",
    "    return [i for i in range(n_channels) if i not in remove]\n",
    "\n",
    "\n",
    "def _apply_channel_filter(arr, keep_idx):\n",
    "    \"\"\"\n",
    "    Applies a channel-selection filter to a voxel or image array.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): Input array of shape [H, W, C] or [H, W]. If 2D,\n",
    "            the array is returned unchanged (no channel dimension to filter).\n",
    "        keep_idx (list of int): List of channel indices (0-based) to retain\n",
    "            along the last axis.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array with the same height and width as `arr`, but with\n",
    "        only the channels in `keep_idx` preserved when `arr` is 3D.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `arr` has a dimensionality other than 2 or 3.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 2:\n",
    "        return arr  # nothing to filter if no channel dim\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Expected [H,W,C], got shape {arr.shape}\")\n",
    "    if len(keep_idx) == arr.shape[-1]:\n",
    "        return arr\n",
    "    return arr[..., keep_idx]\n",
    "\n",
    "\n",
    "def filter_out_by_category(samples, px_model_all, remove_class: str):\n",
    "    \"\"\"\n",
    "    Filters samples based on PCA-based regional categorization, keeping only\n",
    "    those that are not predicted as a specific tumor class.\n",
    "\n",
    "    For each sample, a regional category is computed using\n",
    "    `categorize_sample_regional` and the PCA-based model `px_model_all`.\n",
    "    Samples whose predicted regional label equals `remove_class` are removed.\n",
    "\n",
    "    Args:\n",
    "        samples (list of dict): List of sample dictionaries to be filtered.\n",
    "        px_model_all (PixelPCAContextClassifierAll): Trained pixel-wise model\n",
    "            used inside the regional categorization function.\n",
    "        remove_class (str): Tumor class label to exclude, e.g., 'Papillary'\n",
    "            or 'Follicular'.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: Filtered list of samples for which the regional\n",
    "        prediction is not equal to `remove_class`.\n",
    "    \"\"\"\n",
    "    kept = []\n",
    "    for d in samples:\n",
    "        pred = categorize_sample_regional(px_model_all, d, **REGIONAL_PARAMS)\n",
    "        if pred != remove_class:\n",
    "            kept.append(d)\n",
    "    return kept\n",
    "\n",
    "# ===========================================\n",
    "# 2) Geometric aug (centered rotate + mild zoom + optional flips/noise)\n",
    "# ===========================================\n",
    "def _build_centered_rotation_transform(height, width, angle_rad):\n",
    "    \"\"\"\n",
    "    Builds a projective transform vector for a rotation around the center of\n",
    "    an image, suitable for use with TensorFlow's ImageProjectiveTransform ops.\n",
    "\n",
    "    Args:\n",
    "        height (int or tf.Tensor): Image height in pixels.\n",
    "        width (int or tf.Tensor): Image width in pixels.\n",
    "        angle_rad (float or tf.Tensor): Rotation angle in radians. Positive\n",
    "            values correspond to counterclockwise rotation.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: A 1D tensor of length 8 representing the transformation\n",
    "        parameters [a0, a1, a2, a3, a4, a5, a6, a7], encoding an affine\n",
    "        transform centered on the image.\n",
    "    \"\"\"\n",
    "    angle = tf.cast(angle_rad, tf.float32)\n",
    "    c, s  = tf.math.cos(angle), tf.math.sin(angle)\n",
    "    cx = (tf.cast(width,  tf.float32) - 1.0) / 2.0\n",
    "    cy = (tf.cast(height, tf.float32) - 1.0) / 2.0\n",
    "    a0, a1, a3, a4 = c, -s, s, c\n",
    "    a2 = -a0 * cx - a1 * cy + cx\n",
    "    a5 = -a3 * cx - a4 * cy + cy\n",
    "    return tf.stack([a0, a1, a2, a3, a4, a5, 0.0, 0.0], axis=0)\n",
    "\n",
    "\n",
    "def _rotate_any(img, angle_rad, interpolation=\"bilinear\", fill_mode=\"REFLECT\"):\n",
    "    \"\"\"\n",
    "    Rotates an image by an arbitrary angle about its center using a projective\n",
    "    transform, with configurable interpolation and fill mode.\n",
    "\n",
    "    Args:\n",
    "        img (numpy.ndarray or tf.Tensor): Input image of shape [H, W, C] or [H, W].\n",
    "        angle_rad (float or tf.Tensor): Rotation angle in radians.\n",
    "        interpolation (str): Interpolation mode, either 'bilinear' or 'nearest'.\n",
    "        fill_mode (str): Fill mode passed to ImageProjectiveTransformV3, e.g.,\n",
    "            'REFLECT', 'CONSTANT', 'NEAREST'.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Rotated image tensor with the same spatial dimensions as\n",
    "        the input.\n",
    "    \"\"\"\n",
    "    img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "    H = tf.shape(img)[0]\n",
    "    W = tf.shape(img)[1]\n",
    "    transform = tf.reshape(_build_centered_rotation_transform(H, W, angle_rad), [1, 8])\n",
    "    interp = \"BILINEAR\" if interpolation.lower().startswith(\"bilinear\") else \"NEAREST\"\n",
    "    out = tf.raw_ops.ImageProjectiveTransformV3(\n",
    "        images=tf.expand_dims(img, axis=0),\n",
    "        transforms=transform,\n",
    "        output_shape=tf.stack([H, W]),\n",
    "        interpolation=interp,\n",
    "        fill_mode=fill_mode,\n",
    "        fill_value=0.0,\n",
    "    )\n",
    "    return tf.squeeze(out, axis=0)\n",
    "\n",
    "\n",
    "def augment_triplet(image, image_cutoff, mask):\n",
    "    \"\"\"\n",
    "    Applies a matched geometric and noise augmentation to an image triplet:\n",
    "      - voxel image\n",
    "      - cutoff image\n",
    "      - binary mask\n",
    "\n",
    "    The same random flips, rotation, zoom, and optional Gaussian noise are\n",
    "    applied consistently to all three inputs. Outputs are then cropped/padded\n",
    "    to a fixed size of 256×256.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray or tf.Tensor): Voxel image of shape [H, W, C],\n",
    "            typically float32.\n",
    "        image_cutoff (numpy.ndarray or tf.Tensor): Cutoff voxel image of shape\n",
    "            [H, W, C], typically float32.\n",
    "        mask (numpy.ndarray or tf.Tensor): Binary or label mask of shape\n",
    "            [H, W] or [H, W, 1], integer or float.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - tf.Tensor: Augmented voxel image of shape [256, 256, C'].\n",
    "            - tf.Tensor: Augmented cutoff image of shape [256, 256, C'].\n",
    "            - tf.Tensor: Augmented mask of shape [256, 256], with nearest-\n",
    "              neighbor interpolation preserving label integrity.\n",
    "    \"\"\"\n",
    "    image        = tf.cast(image, tf.float32)\n",
    "    image_cutoff = tf.cast(image_cutoff, tf.float32)\n",
    "    mask         = tf.cast(mask, tf.float32)\n",
    "\n",
    "    if tf.rank(mask) == 2:\n",
    "        mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "    # random params\n",
    "    flip_lr   = tf.random.uniform([], 0.0, 1.0)\n",
    "    flip_ud   = tf.random.uniform([], 0.0, 1.0)\n",
    "    angle_rad = tf.random.uniform([], -15.0 * np.pi / 180.0, 15.0 * np.pi / 180.0)\n",
    "    zoom      = tf.random.uniform([], 0.90, 1.10)\n",
    "    add_noise = tf.random.uniform([], 0.0, 1.0)\n",
    "\n",
    "    # flips\n",
    "    if flip_lr > 0.5:\n",
    "        image        = tf.image.flip_left_right(image)\n",
    "        image_cutoff = tf.image.flip_left_right(image_cutoff)\n",
    "        mask         = tf.image.flip_left_right(mask)\n",
    "    if flip_ud > 0.5:\n",
    "        image        = tf.image.flip_up_down(image)\n",
    "        image_cutoff = tf.image.flip_up_down(image_cutoff)\n",
    "        mask         = tf.image.flip_up_down(mask)\n",
    "\n",
    "    # rotation\n",
    "    image        = _rotate_any(image,        angle_rad, \"bilinear\", \"REFLECT\")\n",
    "    image_cutoff = _rotate_any(image_cutoff, angle_rad, \"bilinear\", \"REFLECT\")\n",
    "    mask         = _rotate_any(mask,         angle_rad, \"nearest\",  \"REFLECT\")\n",
    "\n",
    "    # zoom\n",
    "    H = tf.shape(image)[0]\n",
    "    W = tf.shape(image)[1]\n",
    "    new_h = tf.cast(tf.cast(H, tf.float32) * zoom, tf.int32)\n",
    "    new_w = tf.cast(tf.cast(W, tf.float32) * zoom, tf.int32)\n",
    "    image        = tf.image.resize(image,        [new_h, new_w])\n",
    "    image_cutoff = tf.image.resize(image_cutoff, [new_h, new_w])\n",
    "    mask         = tf.image.resize(mask, [new_h, new_w],\n",
    "                                   method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # center crop/pad to 256x256\n",
    "    image        = tf.image.resize_with_crop_or_pad(image,        256, 256)\n",
    "    image_cutoff = tf.image.resize_with_crop_or_pad(image_cutoff, 256, 256)\n",
    "    mask         = tf.image.resize_with_crop_or_pad(mask,         256, 256)\n",
    "\n",
    "    # noise: separate tensors to avoid channel-shape mismatch\n",
    "    if add_noise > 0.5:\n",
    "        noise_img = tf.random.normal(\n",
    "            tf.shape(image), mean=0.0, stddev=0.001, dtype=tf.float32\n",
    "        )\n",
    "        noise_cut = tf.random.normal(\n",
    "            tf.shape(image_cutoff), mean=0.0, stddev=0.001, dtype=tf.float32\n",
    "        )\n",
    "        image        = image + noise_img\n",
    "        image_cutoff = image_cutoff + noise_cut\n",
    "\n",
    "    return image, image_cutoff, tf.squeeze(mask, axis=-1)\n",
    "\n",
    "# --- simple control over aug counts ---\n",
    "POS_AUGS = 3\n",
    "NEG_AUGS = 1\n",
    "\n",
    "\n",
    "def _has_positive(msk):\n",
    "    \"\"\"\n",
    "    Checks whether a mask contains any non-zero (positive) pixels.\n",
    "\n",
    "    Args:\n",
    "        msk (numpy.ndarray): Input mask of shape [H, W] or [H, W, 1].\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the mask contains at least one positive pixel,\n",
    "        False otherwise.\n",
    "    \"\"\"\n",
    "    m = np.asarray(msk)\n",
    "    if m.ndim == 3 and m.shape[-1] == 1:\n",
    "        m = m[..., 0]\n",
    "    return np.sum(m) > 0\n",
    "\n",
    "\n",
    "def make_augmented_copies(samples, pos_augs=POS_AUGS, neg_augs=NEG_AUGS):\n",
    "    \"\"\"\n",
    "    Creates resized base copies and multiple augmented versions of each sample,\n",
    "    applying voxel-only geometric augmentation and channel selection.\n",
    "\n",
    "    Workflow per sample:\n",
    "        1) Apply channel selection to grayscale voxel and cutoff voxel using\n",
    "           KEEP_VOXEL_CHANNELS / REMOVE_VOXEL_CHANNELS.\n",
    "        2) Resize voxel, cutoff, and mask to 256×256.\n",
    "        3) Store a base (non-augmented) copy with updated fields.\n",
    "        4) If the resized mask contains positive pixels, generate `pos_augs`\n",
    "           augmented copies via `augment_triplet`; otherwise generate `neg_augs`.\n",
    "        5) Remove any stale pixel-level fields ('px_probs', 'px_map', 'px_features').\n",
    "\n",
    "    Args:\n",
    "        samples (list of dict): Original sample dictionaries, each containing:\n",
    "            - 'grayscale_voxel'\n",
    "            - 'grayscale_image_cutoff_voxel'\n",
    "            - optional 'mask'\n",
    "        pos_augs (int): Number of augmentations for positive (tumor-containing)\n",
    "            masks.\n",
    "        neg_augs (int): Number of augmentations for negative (no tumor) masks.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: Expanded list of sample dictionaries including the base\n",
    "        resized samples and their augmented variants. Each dict contains:\n",
    "            - 'grayscale_voxel'\n",
    "            - 'grayscale_image_cutoff_voxel'\n",
    "            - 'mask'\n",
    "            - 'voxel_channels_kept'\n",
    "            - 'cutoff_channels_kept'\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for d in samples:\n",
    "        img = np.asarray(d[\"grayscale_voxel\"], np.float32)              # [H,W,Cv]\n",
    "        cut = np.asarray(d[\"grayscale_image_cutoff_voxel\"], np.float32) # [H,W,Cc]\n",
    "        msk = np.asarray(\n",
    "            d.get(\"mask\", np.zeros(img.shape[:2], np.uint8)),\n",
    "            np.float32,\n",
    "        )\n",
    "\n",
    "        # ---- channel filtering (pre-augmentation) ----\n",
    "        Cv = img.shape[-1] if img.ndim == 3 else 1\n",
    "        Cc = cut.shape[-1] if cut.ndim == 3 else 1\n",
    "\n",
    "        keep_vox = _sanitize_indices(Cv, KEEP_VOXEL_CHANNELS,   REMOVE_VOXEL_CHANNELS)\n",
    "        keep_cut = _sanitize_indices(Cc, KEEP_VOXEL_CHANNELS,  REMOVE_VOXEL_CHANNELS)\n",
    "\n",
    "        # If you also want to filter voxel channels, uncomment:\n",
    "        img = _apply_channel_filter(img, keep_vox)\n",
    "        cut = _apply_channel_filter(cut, keep_cut)   # [H,W,Cc']\n",
    "\n",
    "        # resize to 256x256 once (voxel-only augmentation target)\n",
    "        img0 = tf.image.resize(img, [256, 256]).numpy()\n",
    "        cut0 = tf.image.resize(cut, [256, 256]).numpy()\n",
    "        msk0 = tf.image.resize(\n",
    "            msk[..., None], [256, 256],\n",
    "            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
    "        ).numpy()[..., 0]\n",
    "\n",
    "        # base (unaltered except resize/pad)\n",
    "        base = {\n",
    "            **d,\n",
    "            \"grayscale_voxel\": img0,\n",
    "            \"grayscale_image_cutoff_voxel\": cut0,\n",
    "            \"mask\": msk0,\n",
    "            # helpful metadata for traceability\n",
    "            \"voxel_channels_kept\": keep_vox,\n",
    "            \"cutoff_channels_kept\": keep_cut,\n",
    "        }\n",
    "        # ensure no stale PX fields if present\n",
    "        for k in (\"px_probs\", \"px_map\", \"px_features\"):\n",
    "            base.pop(k, None)\n",
    "        out.append(base)\n",
    "\n",
    "        # augmented copies (voxel-only)\n",
    "        n_aug = pos_augs if _has_positive(msk0) else neg_augs\n",
    "        for _ in range(n_aug):\n",
    "            ai, ac, am = augment_triplet(img0, cut0, msk0)\n",
    "            aug = {\n",
    "                **d,\n",
    "                \"grayscale_voxel\": ai.numpy(),\n",
    "                \"grayscale_image_cutoff_voxel\": ac.numpy(),\n",
    "                \"mask\": am.numpy(),\n",
    "                \"voxel_channels_kept\": keep_vox,\n",
    "                \"cutoff_channels_kept\": keep_cut,\n",
    "            }\n",
    "            for k in (\"px_probs\", \"px_map\", \"px_features\"):\n",
    "                aug.pop(k, None)\n",
    "            out.append(aug)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---- Apply categorize-first filtering (PCA-based) + voxel-only augmentation ----\n",
    "train_px_aug  = make_augmented_copies(train_px_kept, pos_augs=POS_AUGS, neg_augs=NEG_AUGS)\n",
    "val_px_aug  = make_augmented_copies(val_px,  pos_augs=0, neg_augs=0)\n",
    "test_px_aug = make_augmented_copies(test_px, pos_augs=0, neg_augs=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c09c1-4288-4312-8f44-1eaae4171736",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8d58c-1b0a-4734-b24c-d33021dac8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Voxel-only SE-UNet pipeline\n",
    "# (channel selection & regional gating applied upstream)\n",
    "# ===========================================\n",
    "# ------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------\n",
    "KEEP_ANAPLASTIC_WHEN_TARGET = True  # used for reporting only (gating done upstream)\n",
    "assert TARGET_TUMOR in (\"Papillary\", \"Follicular\")\n",
    "\n",
    "# ------------------------------\n",
    "# Masks & input tensors (expects 256×256 from augmentation)\n",
    "# ------------------------------\n",
    "def ensure_mask(d, H, W):\n",
    "    \"\"\"\n",
    "    Constructs a tumor mask for a given sample, ensuring a standardized\n",
    "    shape of [H, W, 1] with float32 values in {0, 1}.\n",
    "\n",
    "    For Normal samples, this returns an all-zero mask. For tumor samples,\n",
    "    it uses the stored 'mask' field from the sample dictionary, resizing\n",
    "    as needed with nearest-neighbor interpolation.\n",
    "\n",
    "    Args:\n",
    "        d (dict): Sample dictionary containing at least 'tissue_type' and\n",
    "            optionally 'mask'.\n",
    "        H (int): Target mask height in pixels.\n",
    "        W (int): Target mask width in pixels.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Binary tumor mask of shape (H, W, 1), dtype float32,\n",
    "        where 1 indicates tumor and 0 indicates background.\n",
    "    \"\"\"\n",
    "    gt = d.get(\"tissue_type\", \"\")\n",
    "    if gt == \"Normal\":\n",
    "        m = np.zeros((H, W), np.uint8)\n",
    "    else:\n",
    "        m = np.asarray(d.get(\"mask\", np.zeros((H, W), np.uint8)), np.uint8)\n",
    "        if m.ndim == 3 and m.shape[-1] == 1:\n",
    "            m = m[..., 0]\n",
    "        if m.shape != (H, W):\n",
    "            m = tf.image.resize(\n",
    "                m[..., None], (H, W),\n",
    "                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
    "            ).numpy().squeeze()\n",
    "    return (m > 0).astype(np.float32)[..., None]\n",
    "\n",
    "\n",
    "def build_vox_inputs(samples):\n",
    "    \"\"\"\n",
    "    Builds voxel input tensors and corresponding tumor masks for training or\n",
    "    evaluation of the voxel-only SE-UNet model.\n",
    "\n",
    "    Args:\n",
    "        samples (list of dict): List of sample dictionaries, each containing:\n",
    "            - 'grayscale_voxel': Voxel image of shape [H, W, C].\n",
    "            - 'tissue_type': Class label (e.g., 'Normal', 'Follicular', 'Papillary').\n",
    "            - optional 'mask': Tumor mask used to derive the ground-truth label.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - numpy.ndarray: X_vox of shape (N, H, W, C), voxel intensities scaled\n",
    "              to the range [0, 1].\n",
    "            - numpy.ndarray: Y of shape (N, H, W, 1), binary tumor masks derived\n",
    "              via `ensure_mask`.\n",
    "    \"\"\"\n",
    "    Xv, Y = [], []\n",
    "    for d in samples:\n",
    "        voxel = np.asarray(d[\"grayscale_voxel\"], np.float32)\n",
    "        H, W, _ = voxel.shape\n",
    "        mask = ensure_mask(d, H, W)\n",
    "        Xv.append(voxel / 255.0)\n",
    "        Y.append(mask)\n",
    "    return np.stack(Xv, 0), np.stack(Y, 0)\n",
    "\n",
    "# ------------------------------\n",
    "# Metrics & Losses\n",
    "# ------------------------------\n",
    "_bce_none = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=\"none\")\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6, empty_score=1.0):\n",
    "    \"\"\"\n",
    "    Computes the mean Dice coefficient over a batch, treating completely empty\n",
    "    masks (both prediction and ground truth) as a special case.\n",
    "\n",
    "    Args:\n",
    "        y_true (tf.Tensor): Ground-truth masks of shape (N, H, W, 1).\n",
    "        y_pred (tf.Tensor): Predicted masks (probabilities) of shape (N, H, W, 1).\n",
    "        smooth (float): Small constant to avoid division by zero.\n",
    "        empty_score (float): Dice score assigned to samples where both\n",
    "            prediction and ground truth are empty.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Scalar mean Dice coefficient over the batch.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 1e-6, 1 - 1e-6)\n",
    "    t = tf.reshape(y_true, (tf.shape(y_true)[0], -1))\n",
    "    p = tf.reshape(y_pred, (tf.shape(y_pred)[0], -1))\n",
    "    inter = tf.reduce_sum(t * p, axis=1)\n",
    "    den = tf.reduce_sum(t + p, axis=1)\n",
    "    dice = (2.0 * inter + smooth) / (den + smooth)\n",
    "\n",
    "    both_empty = tf.logical_and(\n",
    "        tf.equal(tf.reduce_sum(t, 1), 0.0),\n",
    "        tf.equal(tf.reduce_sum(p, 1), 0.0)\n",
    "    )\n",
    "    dice = tf.where(both_empty, tf.fill(tf.shape(dice), empty_score), dice)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "\n",
    "def dice_nonempty(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Computes the mean Dice coefficient over only those samples that contain\n",
    "    at least one positive ground-truth pixel.\n",
    "\n",
    "    Args:\n",
    "        y_true (tf.Tensor): Ground-truth masks of shape (N, H, W, 1).\n",
    "        y_pred (tf.Tensor): Predicted masks (probabilities) of shape (N, H, W, 1).\n",
    "        smooth (float): Small constant to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Scalar mean Dice coefficient over the subset of non-empty\n",
    "        ground-truth masks. Returns 1.0 if there are no non-empty masks.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 1e-6, 1 - 1e-6)\n",
    "    t = tf.reshape(y_true, (tf.shape(y_true)[0], -1))\n",
    "    p = tf.reshape(y_pred, (tf.shape(y_pred)[0], -1))\n",
    "    inter = tf.reduce_sum(t * p, axis=1)\n",
    "    den = tf.reduce_sum(t + p, axis=1)\n",
    "    dice = (2.0 * inter + smooth) / (den + smooth)\n",
    "    nonempty = tf.greater(tf.reduce_sum(t, axis=1), 0.0)\n",
    "    dice = tf.boolean_mask(dice, nonempty)\n",
    "    return tf.cond(\n",
    "        tf.size(dice) > 0,\n",
    "        lambda: tf.reduce_mean(dice),\n",
    "        lambda: tf.constant(1.0),\n",
    "    )\n",
    "\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Computes the mean Intersection-over-Union (IoU) over a batch of masks.\n",
    "\n",
    "    Args:\n",
    "        y_true (tf.Tensor): Ground-truth masks of shape (N, H, W, 1).\n",
    "        y_pred (tf.Tensor): Predicted masks (probabilities) of shape (N, H, W, 1).\n",
    "        smooth (float): Small constant to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Scalar mean IoU across all samples in the batch.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 1e-6, 1 - 1e-6)\n",
    "    t = tf.reshape(y_true, (tf.shape(y_true)[0], -1))\n",
    "    p = tf.reshape(y_pred, (tf.shape(y_pred)[0], -1))\n",
    "    inter = tf.reduce_sum(t * p, axis=1)\n",
    "    union = tf.reduce_sum(t + p, axis=1) - inter\n",
    "    return tf.reduce_mean((inter + smooth) / (union + smooth))\n",
    "\n",
    "\n",
    "def make_weighted_bce(pos_weight_scalar):\n",
    "    \"\"\"\n",
    "    Creates a weighted binary cross-entropy loss function that upweights\n",
    "    positive pixels relative to negative pixels.\n",
    "\n",
    "    Args:\n",
    "        pos_weight_scalar (float): Positive class weight. A value > 1 increases\n",
    "            the contribution of tumor pixels to the loss.\n",
    "\n",
    "    Returns:\n",
    "        callable: A loss function `weighted_bce(y_true, y_pred)` suitable for\n",
    "        use in model.compile(), which computes a per-image, per-pixel weighted\n",
    "        binary cross-entropy and averages over the batch.\n",
    "    \"\"\"\n",
    "    pw = tf.constant(float(pos_weight_scalar), dtype=tf.float32)\n",
    "\n",
    "    def weighted_bce(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 1e-6, 1 - 1e-6)\n",
    "        per_px = _bce_none(y_true, y_pred)\n",
    "        weights = 1.0 + (pw - 1.0) * tf.squeeze(y_true, -1)\n",
    "        num = tf.reduce_sum(weights * per_px, axis=[1, 2])\n",
    "        den = tf.reduce_sum(weights, axis=[1, 2]) + 1e-6\n",
    "        return tf.reduce_mean(num / den)\n",
    "\n",
    "    return weighted_bce\n",
    "\n",
    "\n",
    "def tversky_index(y_true, y_pred, alpha=0.7, beta=0.3, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Computes the Tversky index for a batch of predictions, a generalization\n",
    "    of Dice/IoU that allows asymmetric weighting of false positives and\n",
    "    false negatives.\n",
    "\n",
    "    Args:\n",
    "        y_true (tf.Tensor): Ground-truth masks of shape (N, H, W, 1).\n",
    "        y_pred (tf.Tensor): Predicted masks (probabilities) of shape (N, H, W, 1).\n",
    "        alpha (float): Weight for false positives.\n",
    "        beta (float): Weight for false negatives.\n",
    "        smooth (float): Small constant to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Scalar mean Tversky index across the batch.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 1e-6, 1 - 1e-6)\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    fp = tf.reduce_sum((1.0 - y_true) * y_pred, axis=[1, 2, 3])\n",
    "    fn = tf.reduce_sum(y_true * (1.0 - y_pred), axis=[1, 2, 3])\n",
    "    return tf.reduce_mean((tp + smooth) / (tp + alpha * fp + beta * fn + smooth))\n",
    "\n",
    "\n",
    "def focal_tversky_loss(alpha=0.7, beta=0.3, gamma=0.75):\n",
    "    \"\"\"\n",
    "    Builds a Focal Tversky loss function, which focuses learning on hard\n",
    "    examples by applying a non-linear penalty on the Tversky index.\n",
    "\n",
    "    Args:\n",
    "        alpha (float): Weight for false positives in the Tversky index.\n",
    "        beta (float): Weight for false negatives in the Tversky index.\n",
    "        gamma (float): Focusing parameter; larger values place more emphasis\n",
    "            on misclassified or difficult examples.\n",
    "\n",
    "    Returns:\n",
    "        callable: A loss function `_loss(y_true, y_pred)` that computes\n",
    "        (1 - TverskyIndex)^gamma averaged over the batch.\n",
    "    \"\"\"\n",
    "    def _loss(y_true, y_pred):\n",
    "        t = tversky_index(y_true, y_pred, alpha=alpha, beta=beta)\n",
    "        return tf.pow(1.0 - t, gamma)\n",
    "\n",
    "    return _loss\n",
    "\n",
    "\n",
    "def make_combined_loss(pos_weight_scalar):\n",
    "    \"\"\"\n",
    "    Constructs a composite loss function combining weighted binary\n",
    "    cross-entropy and Focal Tversky loss in equal proportion.\n",
    "\n",
    "    Args:\n",
    "        pos_weight_scalar (float): Positive class weight passed to the\n",
    "            weighted BCE component.\n",
    "\n",
    "    Returns:\n",
    "        callable: A loss function `_loss(y_true, y_pred)` that computes\n",
    "        the mean of:\n",
    "            0.5 * weighted_bce(y_true, y_pred) +\n",
    "            0.5 * focal_tversky_loss(y_true, y_pred).\n",
    "    \"\"\"\n",
    "    wbce = make_weighted_bce(pos_weight_scalar)\n",
    "    ftv = focal_tversky_loss(alpha=0.7, beta=0.3, gamma=0.75)\n",
    "\n",
    "    def _loss(y_true, y_pred):\n",
    "        return 0.5 * wbce(y_true, y_pred) + 0.5 * ftv(y_true, y_pred)\n",
    "\n",
    "    return _loss\n",
    "\n",
    "# ------------------------------\n",
    "# SE-UNet (voxel-only)\n",
    "# ------------------------------\n",
    "def squeeze_excite_block(x, reduction=16):\n",
    "    \"\"\"\n",
    "    Applies a squeeze-and-excitation (SE) attention block to a feature map,\n",
    "    adaptively reweighting channels based on global context.\n",
    "\n",
    "    Args:\n",
    "        x (tf.Tensor): Input feature map of shape (N, H, W, C).\n",
    "        reduction (int): Channel reduction factor in the bottleneck layer\n",
    "            of the SE block. Larger values reduce parameter count.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Output feature map of the same shape as `x`, with channels\n",
    "        rescaled by learned attention weights in [0, 1].\n",
    "    \"\"\"\n",
    "    c = x.shape[-1]\n",
    "    s = GlobalAveragePooling2D()(x)\n",
    "    s = Reshape((1, 1, c))(s)\n",
    "    s = Dense(max(c // reduction, 4), activation=\"relu\")(s)\n",
    "    s = Dense(c, activation=\"sigmoid\")(s)\n",
    "    return Multiply()([x, s])\n",
    "\n",
    "\n",
    "def enc_block_SE(x, filters, p_drop=0.10):\n",
    "    \"\"\"\n",
    "    Encoder block with optional squeeze-and-excitation, used in the\n",
    "    downsampling path of the SE-UNet.\n",
    "\n",
    "    The block performs:\n",
    "        - Conv2D + BatchNorm (+ SE for higher channel counts)\n",
    "        - SpatialDropout2D\n",
    "        - Strided Conv2D for downsampling\n",
    "\n",
    "    Args:\n",
    "        x (tf.Tensor): Input feature map.\n",
    "        filters (int): Number of convolution filters in this block.\n",
    "        p_drop (float): Dropout probability for SpatialDropout2D.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - tf.Tensor: Feature map before downsampling (skip connection).\n",
    "            - tf.Tensor: Downsampled feature map passed to the next encoder level.\n",
    "    \"\"\"\n",
    "    x = Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if filters >= 128:\n",
    "        x = squeeze_excite_block(x)\n",
    "    x = SpatialDropout2D(p_drop)(x)\n",
    "    p = Conv2D(filters, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    return x, p\n",
    "\n",
    "\n",
    "def dec_block_SE(x, skip, filters):\n",
    "    \"\"\"\n",
    "    Decoder block with skip connections, used in the upsampling path of the\n",
    "    SE-UNet.\n",
    "\n",
    "    The block performs:\n",
    "        - Upsampling by a factor of 2\n",
    "        - Concatenation with the corresponding encoder skip feature map\n",
    "        - Two Conv2D + ReLU layers with BatchNorm on the first\n",
    "\n",
    "    Args:\n",
    "        x (tf.Tensor): Input feature map from the deeper layer.\n",
    "        skip (tf.Tensor): Skip-connection feature map from the encoder path.\n",
    "        filters (int): Number of convolution filters in this block.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Output feature map after upsampling and refinement.\n",
    "    \"\"\"\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_unet_vox_only(vox_ch=23):\n",
    "    \"\"\"\n",
    "    Builds a 2D SE-UNet model that operates on voxel-only DOCI inputs for\n",
    "    tumor segmentation.\n",
    "\n",
    "    The architecture includes:\n",
    "        - An initial Conv2D stem.\n",
    "        - Five encoder blocks (with SE in deeper layers).\n",
    "        - A bottleneck with Conv2D, BatchNorm, and Dropout.\n",
    "        - Five decoder blocks with skip connections.\n",
    "        - A final 1×1 convolution with sigmoid activation for output masks.\n",
    "\n",
    "    Args:\n",
    "        vox_ch (int): Number of input voxel channels (C) in the grayscale\n",
    "            voxel image.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Compiled Keras model with input shape\n",
    "        (256, 256, vox_ch) and a single-channel sigmoid output named\n",
    "        'seg_output'.\n",
    "    \"\"\"\n",
    "    vox_in = Input((256, 256, vox_ch), name=\"vox_in\")\n",
    "    x0 = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(vox_in)\n",
    "    e1, p1 = enc_block_SE(x0,   32, 0.10)\n",
    "    e2, p2 = enc_block_SE(p1,   64, 0.10)\n",
    "    e3, p3 = enc_block_SE(p2,  128, 0.10)\n",
    "    e4, p4 = enc_block_SE(p3,  256, 0.10)\n",
    "    e5, p5 = enc_block_SE(p4,  512, 0.15)\n",
    "\n",
    "    b = Conv2D(1024, 3, padding=\"same\", activation=\"relu\")(p5)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = Dropout(0.2)(b)\n",
    "\n",
    "    d5 = dec_block_SE(b,  e5, 512)\n",
    "    d4 = dec_block_SE(d5, e4, 256)\n",
    "    d3 = dec_block_SE(d4, e3, 128)\n",
    "    d2 = dec_block_SE(d3, e2,  64)\n",
    "    d1 = dec_block_SE(d2, e1,  32)\n",
    "\n",
    "    out = Conv2D(1, 1, activation=\"sigmoid\", name=\"seg_output\")(d1)\n",
    "    return Model(vox_in, out, name=\"SE_UNet_VoxelOnly\")\n",
    "\n",
    "# ------------------------------\n",
    "# Build filtered datasets (already gated & augmented upstream)\n",
    "# ------------------------------\n",
    "train_f = train_px_aug\n",
    "val_f   = val_px_aug\n",
    "test_f  = test_px_aug\n",
    "\n",
    "print(\n",
    "    \"Example channels:\",\n",
    "    f\"train C={np.asarray(train_f[0]['grayscale_voxel']).shape[-1]}\",\n",
    "    f\"val C={np.asarray(val_f[0]['grayscale_voxel']).shape[-1]}\",\n",
    "    f\"test C={np.asarray(test_f[0]['grayscale_voxel']).shape[-1]}\",\n",
    ")\n",
    "\n",
    "Xtr_vox, Ytr = build_vox_inputs(train_f)\n",
    "Xva_vox, Yva = build_vox_inputs(val_f)\n",
    "Xte_vox, Yte = build_vox_inputs(test_f)\n",
    "\n",
    "print(\n",
    "    f\"Kept after regional gate (Normal + {TARGET_TUMOR}\"\n",
    "    f\"{' + Anaplastic' if KEEP_ANAPLASTIC_WHEN_TARGET else ''}): \"\n",
    "    f\"train={len(train_f)}, val={len(val_f)}, test={len(test_f)}\"\n",
    ")\n",
    "print(\n",
    "    \"Shapes:\",\n",
    "    \"\\n  train:\", Xtr_vox.shape, Ytr.shape,\n",
    "    \"\\n  val:  \", Xva_vox.shape, Yva.shape,\n",
    "    \"\\n  test: \", Xte_vox.shape, Yte.shape,\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Compile & train\n",
    "# ------------------------------\n",
    "pos_frac = float(np.mean(Ytr > 0.5)) if Ytr.size else 0.5\n",
    "neg_frac = 1.0 - pos_frac\n",
    "pos_weight_val = min(5.0, float(neg_frac / (pos_frac + 1e-6)))\n",
    "print(f\"pos_frac ~ {pos_frac:.4f} | pos_weight (capped) ~ {pos_weight_val:.3f}\")\n",
    "\n",
    "model = build_unet_vox_only(vox_ch=Xtr_vox.shape[-1])\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=3e-4),\n",
    "    loss=make_combined_loss(pos_weight_val),\n",
    "    metrics=[dice_coef, dice_nonempty, iou_coef],\n",
    ")\n",
    "\n",
    "ckpt_path = (\n",
    "    f\"test1.weights.h5\")\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor=\"val_dice_nonempty\", mode=\"max\", patience=20, restore_best_weights=True, verbose=1, )\n",
    "\n",
    "ckpt = ModelCheckpoint(\n",
    "    ckpt_path, monitor=\"val_dice_nonempty\", mode=\"max\", save_best_only=True, save_weights_only=True, verbose=1, )\n",
    "\n",
    "rlrop = ReduceLROnPlateau(\n",
    "    monitor=\"val_dice_nonempty\", mode=\"max\", factor=0.5, patience=6, min_lr=1e-6, verbose=1, )\n",
    "\n",
    "# ------------------------------\n",
    "# Evaluation helper\n",
    "# ------------------------------\n",
    "def evaluate(y_true, y_prob, t):\n",
    "    \"\"\"\n",
    "    Computes thresholded Dice and IoU statistics over a batch of predictions.\n",
    "\n",
    "    For each sample, predictions are binarized at threshold `t`, and Dice and\n",
    "    IoU are computed at the image level. Empty cases (both prediction and\n",
    "    ground truth empty) receive perfect scores by definition.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): Ground-truth masks of shape (N, H, W, 1),\n",
    "            with values in {0, 1}.\n",
    "        y_prob (numpy.ndarray): Predicted probabilities of shape (N, H, W, 1),\n",
    "            with values in [0, 1].\n",
    "        t (float): Threshold for converting probabilities to binary masks.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - tuple: (dice_mean, dice_std, dice_median)\n",
    "            - tuple: (iou_mean,  iou_std,  iou_median)\n",
    "    \"\"\"\n",
    "    y_true = (y_true > 0.5).astype(np.uint8)\n",
    "    y_pred = (y_prob >= t).astype(np.uint8)\n",
    "\n",
    "    dices, ious = [], []\n",
    "    for i in range(len(y_true)):\n",
    "        gt = y_true[i, ..., 0]\n",
    "        pr = y_pred[i, ..., 0]\n",
    "        inter = np.logical_and(gt, pr).sum()\n",
    "\n",
    "        den_d = gt.sum() + pr.sum()\n",
    "        dice = (2 * inter) / (den_d + 1e-6) if den_d > 0 else 1.0\n",
    "\n",
    "        union = np.logical_or(gt, pr).sum()\n",
    "        iou = inter / (union + 1e-6) if union > 0 else 1.0\n",
    "\n",
    "        dices.append(dice)\n",
    "        ious.append(iou)\n",
    "\n",
    "    return (\n",
    "        (np.mean(dices), np.std(dices), np.median(dices)),\n",
    "        (np.mean(ious),  np.std(ious),  np.median(ious)),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd36b09-fb87-4799-8ea1-60791d126746",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4400ad6-2c33-4c9f-a18d-72d75092eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Channel policy (already applied upstream)\n",
    "# ------------------------------\n",
    "print(f\"[ChannelFilter] Using {Xtr_vox.shape[-1]} channels.\")\n",
    "\n",
    "# ------------------------------\n",
    "# Fit model\n",
    "# ------------------------------\n",
    "history = model.fit(\n",
    "    Xtr_vox, Ytr,\n",
    "    validation_data=(Xva_vox, Yva),\n",
    "    batch_size=2,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    callbacks=[ckpt, rlrop, early],\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Threshold calibration + evaluation\n",
    "# ------------------------------\n",
    "def _mean_dice_for_threshold(y_true, y_prob, t):\n",
    "    \"\"\"\n",
    "    Computes the mean Dice coefficient over a batch for a given\n",
    "    binarization threshold.\n",
    "\n",
    "    Ground truth masks are binarized at 0.5, while predicted probabilities\n",
    "    are binarized at threshold `t`. Dice is computed per image and then\n",
    "    averaged across the batch. Empty cases (no positive pixels in either\n",
    "    prediction or ground truth) receive a perfect score of 1.0.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): Ground-truth masks of shape (N, H, W, 1),\n",
    "            with values in {0, 1}.\n",
    "        y_prob (numpy.ndarray): Predicted probabilities of shape (N, H, W, 1),\n",
    "            with values in [0, 1].\n",
    "        t (float): Threshold used to convert predicted probabilities into\n",
    "            binary masks.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean Dice coefficient across all samples in the batch at\n",
    "        threshold `t`.\n",
    "    \"\"\"\n",
    "    y_true_bin = (y_true > 0.5).astype(np.uint8)\n",
    "    y_pred_bin = (y_prob >= t).astype(np.uint8)\n",
    "\n",
    "    dices = []\n",
    "    for i in range(len(y_true_bin)):\n",
    "        gt = y_true_bin[i, ..., 0]\n",
    "        pr = y_pred_bin[i, ..., 0]\n",
    "        inter = np.logical_and(gt, pr).sum()\n",
    "        den = gt.sum() + pr.sum()\n",
    "        d = (2 * inter) / (den + 1e-6) if den > 0 else 1.0\n",
    "        dices.append(d)\n",
    "    return float(np.mean(dices)) if dices else 1.0\n",
    "\n",
    "\n",
    "def best_dice_threshold(y_true, y_prob, grid=np.linspace(0.2, 0.9, 29)):\n",
    "    \"\"\"\n",
    "    Searches over a grid of thresholds to find the value that maximizes\n",
    "    the mean Dice coefficient on a given dataset.\n",
    "\n",
    "    For each candidate threshold in `grid`, the function computes the mean\n",
    "    Dice using `_mean_dice_for_threshold` and keeps track of the best-performing\n",
    "    threshold.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): Ground-truth masks of shape (N, H, W, 1),\n",
    "            with values in {0, 1}.\n",
    "        y_prob (numpy.ndarray): Predicted probabilities of shape (N, H, W, 1),\n",
    "            with values in [0, 1].\n",
    "        grid (numpy.ndarray): 1D array of threshold values to scan, typically\n",
    "            in the interval [0, 1].\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - float: Best threshold (t*) that yields the highest mean Dice.\n",
    "            - float: Corresponding mean Dice value at t*.\n",
    "    \"\"\"\n",
    "    best_t, best_d = 0.5, -1.0\n",
    "    for t in grid:\n",
    "        md = _mean_dice_for_threshold(y_true, y_prob, t)\n",
    "        if md > best_d:\n",
    "            best_d, best_t = md, float(t)\n",
    "    return best_t, best_d\n",
    "\n",
    "\n",
    "# --- Calibrate on validation set ---\n",
    "val_probs = model.predict(Xva_vox, batch_size=2)\n",
    "t_star, dice_val = best_dice_threshold(Yva, val_probs)\n",
    "print(f\"[CAL] t*={t_star:.3f} (VAL mean Dice={dice_val:.3f})\")\n",
    "\n",
    "# --- Evaluate on test set ---\n",
    "test_probs = model.predict(Xte_vox, batch_size=2)\n",
    "(d_mean, d_std, d_med), (i_mean, i_std, i_med) = evaluate(Yte, test_probs, t_star)\n",
    "\n",
    "print(f\"[TEST] Dice mean={d_mean:.3f} ± {d_std:.3f} | median={d_med:.3f}\")\n",
    "print(f\"[TEST]  IoU  mean={i_mean:.3f} ± {i_std:.3f} | median={i_med:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b8a97-995d-4b9b-83eb-00c303484f92",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2d2ae-154a-46e9-8c16-3eb516b59ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights saved for the voxel-only model\n",
    "model.load_weights(\n",
    "    \"test1.weights.h5\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# UID helper\n",
    "# ---------------------------------------------------------------------\n",
    "def sample_uid(d):\n",
    "    \"\"\"\n",
    "    Generates a stable, human-readable unique identifier string for a sample\n",
    "    dictionary based on preferred metadata fields or, if unavailable, on\n",
    "    voxel tensor shapes.\n",
    "\n",
    "    Priority is given to common identifying keys such as:\n",
    "    'uid', 'id', 'sample_id', 'image_name', 'name', 'file', 'path'.\n",
    "\n",
    "    If none of these fields exist, a fallback UID is constructed from:\n",
    "        - The shape of the grayscale voxel tensor\n",
    "        - The shape of the grayscale cutoff voxel\n",
    "        - A modulo hash of the voxel size for collision reduction\n",
    "\n",
    "    Args:\n",
    "        d (dict): Sample dictionary containing voxel and cutoff voxel arrays,\n",
    "                  and optionally metadata fields for identification.\n",
    "\n",
    "    Returns:\n",
    "        str: Stable identifier string for the sample, suitable for filenames,\n",
    "             figure labels, or logging.\n",
    "    \"\"\"\n",
    "    for k in (\"uid\", \"id\", \"sample_id\", \"image_name\", \"name\", \"file\", \"path\"):\n",
    "        if k in d and d[k] is not None:\n",
    "            return str(d[k])\n",
    "    v   = np.asarray(d[\"grayscale_voxel\"])\n",
    "    cut = np.asarray(d[\"grayscale_image_cutoff_voxel\"])\n",
    "    return f\"auto:{v.shape}-{cut.shape}-{int(v.size % 997)}\"\n",
    "\n",
    "\n",
    "U_gt = [sample_uid(d) for d in test_f]\n",
    "print(\"TEST shapes:\", Xte_vox.shape, Yte.shape, f\"uids={len(U_gt)}\")\n",
    "\n",
    "# --- Predict on test set (same tensors used for metrics) ---\n",
    "test_probs = model.predict(Xte_vox, batch_size=2)\n",
    "\n",
    "# Sanity checks\n",
    "assert test_probs.shape[0] == Yte.shape[0] == len(U_gt)\n",
    "assert Xte_vox.shape[:3] == Yte.shape[:3] == test_probs.shape[:3]\n",
    "\n",
    "GT_mask = Yte          # [N,H,W,1]\n",
    "PROBS   = test_probs   # [N,H,W,1]\n",
    "\n",
    "# Use previously calibrated t_star if present; else compute per-image Otsu fallback\n",
    "t_star_value = globals().get(\"t_star\", None)\n",
    "use_global_thresh = t_star_value is not None\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Per-sample visualization: CNN P(Tumor) / GT / Thresholded Pred\n",
    "# ---------------------------------------------------------------------\n",
    "for i in range(PROBS.shape[0]):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    # --- Extract data ---\n",
    "    voxel_ch0 = Xte_vox[i, ..., 0]      # <-- FIRST CHANNEL OF VOXEL STACK\n",
    "    pt_cnn    = PROBS[i, ..., 0]        # CNN probability map\n",
    "    gt        = GT_mask[i, ..., 0]      # GT mask\n",
    "\n",
    "    # --- Threshold selection ---\n",
    "    if use_global_thresh:\n",
    "        t_use = float(t_star_value)\n",
    "    else:\n",
    "        try:\n",
    "            t_use = float(threshold_otsu(pt_cnn))\n",
    "        except Exception:\n",
    "            t_use = 0.5\n",
    "\n",
    "    pred = (pt_cnn >= t_use).astype(np.uint8)\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # PANEL 1: First voxel channel (instead of PCA or CNN probs)\n",
    "    # ---------------------------------------------------------------------\n",
    "    ax[0].imshow(voxel_ch0, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Voxel: Channel 0\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    # PANEL 2: Ground-truth mask\n",
    "    ax[1].imshow(gt, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    ax[1].set_title(\"GT\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    # PANEL 3: Thresholded prediction\n",
    "    ax[2].imshow(pred, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    ax[2].set_title(f\"Pred (t={t_use:.2f})\")\n",
    "    ax[2].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"sample: {U_gt[i]}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132bebb2-d687-4605-be04-4e3416b801b9",
   "metadata": {},
   "source": [
    "# Final Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2289582-68da-4730-91e6-33f7f33b88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Basic helpers\n",
    "# ----------------------------\n",
    "def _ensure_2d(mask):\n",
    "    \"\"\"\n",
    "    Convert a mask array to a 2D uint8 array.\n",
    "\n",
    "    Accepts inputs of shape [H,W] or [H,W,1]. Any trailing singleton channel\n",
    "    dimension is removed. Values are cast to uint8.\n",
    "\n",
    "    Args:\n",
    "        mask (array-like): Input mask tensor of shape [H,W] or [H,W,1].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 2D uint8 mask of shape [H,W].\n",
    "    \"\"\"\n",
    "    arr = np.asarray(mask)\n",
    "    if arr.ndim == 3:\n",
    "        arr = arr[..., 0]\n",
    "    return arr.astype(np.uint8)\n",
    "\n",
    "\n",
    "def _threshold_probs(y_prob, t):\n",
    "    \"\"\"\n",
    "    Threshold probability maps at a fixed scalar threshold.\n",
    "\n",
    "    Handles tensors of shape [N,H,W,1] or [N,H,W] and returns a binary mask.\n",
    "\n",
    "    Args:\n",
    "        y_prob (np.ndarray): Probability maps.\n",
    "        t (float): Threshold in [0,1].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Binary masks (uint8) with same spatial dimensions.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(y_prob)\n",
    "    if arr.ndim == 4:\n",
    "        arr = arr[..., 0]\n",
    "    return (arr >= float(t)).astype(np.uint8)\n",
    "\n",
    "\n",
    "def dice_per_image(gt, pr, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute Dice coefficient for a single 2D image.\n",
    "\n",
    "    Args:\n",
    "        gt (array-like): Ground-truth mask [H,W] or [H,W,1].\n",
    "        pr (array-like): Predicted mask [H,W] or [H,W,1].\n",
    "        eps (float): Numerical stability constant.\n",
    "\n",
    "    Returns:\n",
    "        float: Dice score for one image.\n",
    "    \"\"\"\n",
    "    gt = _ensure_2d(gt)\n",
    "    pr = _ensure_2d(pr)\n",
    "    inter = np.logical_and(gt, pr).sum()\n",
    "    den   = gt.sum() + pr.sum()\n",
    "    return (2 * inter) / (den + eps) if den > 0 else 1.0\n",
    "\n",
    "\n",
    "def iou_per_image(gt, pr, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute IoU (Jaccard index) for a single 2D image.\n",
    "\n",
    "    Args:\n",
    "        gt (array-like): Ground-truth mask.\n",
    "        pr (array-like): Predicted mask.\n",
    "        eps (float): Numerical stability constant.\n",
    "\n",
    "    Returns:\n",
    "        float: IoU score.\n",
    "    \"\"\"\n",
    "    gt = _ensure_2d(gt)\n",
    "    pr = _ensure_2d(pr)\n",
    "    inter = np.logical_and(gt, pr).sum()\n",
    "    union = np.logical_or(gt, pr).sum()\n",
    "    return inter / (union + eps) if union > 0 else 1.0\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Threshold calibration + simple Dice/IoU\n",
    "# ----------------------------\n",
    "def best_dice_threshold(y_true, y_prob, grid=np.linspace(0.2, 0.9, 29)):\n",
    "    \"\"\"\n",
    "    Brute-force search for the optimal scalar threshold that maximizes\n",
    "    mean per-image Dice on a validation set.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground-truth masks [N,H,W,1].\n",
    "        y_prob (np.ndarray): Predicted probabilities [N,H,W,1].\n",
    "        grid (iterable): Threshold values to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        (float, float):\n",
    "            best_threshold : threshold achieving maximum mean Dice\n",
    "            best_mean_dice : corresponding mean Dice value\n",
    "    \"\"\"\n",
    "    y_true_bin = (y_true > 0.5).astype(np.uint8)\n",
    "    best_t, best_d = 0.5, -1.0\n",
    "\n",
    "    for t in grid:\n",
    "        y_pred_bin = _threshold_probs(y_prob, t)\n",
    "        dices = []\n",
    "        for i in range(len(y_true_bin)):\n",
    "            gt = y_true_bin[i, ..., 0]\n",
    "            pr = y_pred_bin[i, ...]\n",
    "            dices.append(dice_per_image(gt, pr))\n",
    "        md = float(np.mean(dices)) if dices else 1.0\n",
    "        if md > best_d:\n",
    "            best_d, best_t = md, float(t)\n",
    "\n",
    "    return best_t, best_d\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_prob, t):\n",
    "    \"\"\"\n",
    "    Compute mean/std/median Dice and IoU for a fixed threshold.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground-truth masks [N,H,W,1].\n",
    "        y_prob (np.ndarray): CNN probability maps [N,H,W,1].\n",
    "        t (float): Threshold value.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "          dice_stats = (mean, std, median)\n",
    "          iou_stats  = (mean, std, median)\n",
    "    \"\"\"\n",
    "    y_true_bin = (y_true > 0.5).astype(np.uint8)\n",
    "    y_pred_bin = _threshold_probs(y_prob, t)\n",
    "\n",
    "    dices, ious = [], []\n",
    "    for i in range(len(y_true_bin)):\n",
    "        gt = y_true_bin[i, ..., 0]\n",
    "        pr = y_pred_bin[i, ...]\n",
    "        dices.append(dice_per_image(gt, pr))\n",
    "        ious.append(iou_per_image(gt, pr))\n",
    "\n",
    "    dices = np.asarray(dices)\n",
    "    ious  = np.asarray(ious)\n",
    "\n",
    "    return (\n",
    "        (float(dices.mean()), float(dices.std()), float(np.median(dices))),\n",
    "        (float(ious.mean()),  float(ious.std()),  float(np.median(ious))),\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Predict once on all splits ---\n",
    "train_probs = model.predict(Xtr_vox, batch_size=2)\n",
    "val_probs   = model.predict(Xva_vox, batch_size=2)\n",
    "test_probs  = model.predict(Xte_vox, batch_size=2)\n",
    "\n",
    "# Optional sanity checks\n",
    "assert train_probs.shape[0] == Ytr.shape[0]\n",
    "assert val_probs.shape[0]   == Yva.shape[0]\n",
    "assert test_probs.shape[0]  == Yte.shape[0]\n",
    "\n",
    "# --- Calibrate threshold on validation set ---\n",
    "t_star, dice_val = best_dice_threshold(Yva, val_probs)\n",
    "print(f\"[CAL] t*={t_star:.3f} (VAL mean Dice={dice_val:.3f})\")\n",
    "\n",
    "# --- Basic test-set evaluation ---\n",
    "(d_mean, d_std, d_med), (i_mean, i_std, i_med) = evaluate(Yte, test_probs, t_star)\n",
    "print(f\"[TEST] Dice mean={d_mean:.3f} ± {d_std:.3f} | median={d_med:.3f}\")\n",
    "print(f\"[TEST]  IoU  mean={i_mean:.3f} ± {i_std:.3f} | median={i_med:.3f}\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Rich metrics for imbalanced data\n",
    "# ============================\n",
    "def _boundary_band(mask, radius=2):\n",
    "    \"\"\"\n",
    "    Compute a thin boundary band around mask edges using morphological\n",
    "    dilation/erosion.\n",
    "\n",
    "    Used for boundary-based F1 evaluation (precision/recall on edges).\n",
    "\n",
    "    Args:\n",
    "        mask (array-like): Binary 2D mask.\n",
    "        radius (int): Number of iterations for dilation/erosion.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Binary [H,W] mask representing boundary pixels.\n",
    "    \"\"\"\n",
    "    m = _ensure_2d(mask) > 0\n",
    "    if m.size == 0:\n",
    "        return np.zeros_like(m, dtype=np.uint8)\n",
    "    dil = binary_dilation(m, iterations=radius)\n",
    "    ero = binary_erosion(m,  iterations=radius)\n",
    "    return np.logical_xor(dil, ero).astype(np.uint8)\n",
    "\n",
    "\n",
    "def dice_nonempty_mean(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute average Dice over ONLY images with non-empty ground-truth masks.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): [N,H,W] or [N,H,W,1] GT masks.\n",
    "        y_pred (np.ndarray): [N,H,W] predicted masks.\n",
    "\n",
    "    Returns:\n",
    "        (float, np.ndarray):\n",
    "            mean Dice over nonempty images,\n",
    "            per-image Dice array.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for i in range(len(y_true)):\n",
    "        gt = _ensure_2d(y_true[i])\n",
    "        pr = _ensure_2d(y_pred[i])\n",
    "        if gt.sum() > 0:\n",
    "            scores.append(dice_per_image(gt, pr))\n",
    "    return (np.mean(scores) if scores else 1.0), np.array(scores)\n",
    "\n",
    "\n",
    "def empty_fp_penalty_mean(y_true, y_pred, tissue_masks=None):\n",
    "    \"\"\"\n",
    "    Evaluate false-positive performance only on images with empty GT.\n",
    "\n",
    "    For empty images:\n",
    "        score = 1 - FP_fraction,\n",
    "    where FP_fraction is measured either within the tissue region (if provided)\n",
    "    or over all pixels.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground-truth masks.\n",
    "        y_pred (np.ndarray): Predicted masks.\n",
    "        tissue_masks (np.ndarray or None):\n",
    "            Optional binary mask indicating tissue pixels.\n",
    "\n",
    "    Returns:\n",
    "        (float, np.ndarray):\n",
    "            mean penalty across empty-GT images,\n",
    "            per-image penalty values.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for i in range(len(y_true)):\n",
    "        gt = _ensure_2d(y_true[i])\n",
    "        if gt.sum() == 0:\n",
    "            pr = _ensure_2d(y_pred[i])\n",
    "            if tissue_masks is not None:\n",
    "                T = (tissue_masks[i] > 0).astype(np.uint8)\n",
    "                denom = max(1, T.sum())\n",
    "                fp = (pr * (1 - gt) * T).sum()\n",
    "            else:\n",
    "                denom = pr.size\n",
    "                fp = (pr * (1 - gt)).sum()\n",
    "            scores.append(1.0 - (fp / denom))\n",
    "    return (np.mean(scores) if scores else 1.0), np.array(scores)\n",
    "\n",
    "\n",
    "def boundary_f1_mean(y_true, y_pred, radius=2, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute boundary F1 score by comparing boundary pixels of GT and prediction.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground truth masks.\n",
    "        y_pred (np.ndarray): Predicted masks.\n",
    "        radius (int): Boundary thickness.\n",
    "        eps (float): Stability constant.\n",
    "\n",
    "    Returns:\n",
    "        (float, np.ndarray):\n",
    "            mean boundary F1, per-image F1 scores.\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    for i in range(len(y_true)):\n",
    "        gt = _ensure_2d(y_true[i])\n",
    "        pr = _ensure_2d(y_pred[i])\n",
    "        Bgt = _boundary_band(gt, radius=radius)\n",
    "        Bpr = _boundary_band(pr, radius=radius)\n",
    "        tp = np.logical_and(Bgt, Bpr).sum()\n",
    "        fp = np.logical_and((1 - Bgt), Bpr).sum()\n",
    "        fn = np.logical_and(Bgt, (1 - Bpr)).sum()\n",
    "        prec = tp / (tp + fp + eps)\n",
    "        rec  = tp / (tp + fn + eps)\n",
    "        f1   = (2 * prec * rec) / (prec + rec + eps)\n",
    "        vals.append(f1)\n",
    "    return float(np.mean(vals)), np.array(vals)\n",
    "\n",
    "\n",
    "def lesion_f1_mean(y_true, y_pred, iou_thresh=0.5):\n",
    "    \"\"\"\n",
    "    Lesion-level F1 score: computes detection F1 over connected components,\n",
    "    using IoU >= threshold as the matching criterion.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): GT masks.\n",
    "        y_pred (np.ndarray): Pred masks.\n",
    "        iou_thresh (float): IoU threshold for declaring a match.\n",
    "\n",
    "    Returns:\n",
    "        (float, np.ndarray):\n",
    "            mean lesion-level F1, per-image F1 values.\n",
    "    \"\"\"\n",
    "    def _components(mask):\n",
    "        lab, n = label(mask > 0)\n",
    "        return [(lab == k).astype(np.uint8) for k in range(1, n + 1)]\n",
    "\n",
    "    f1s = []\n",
    "    for i in range(len(y_true)):\n",
    "        gt = _ensure_2d(y_true[i])\n",
    "        pr = _ensure_2d(y_pred[i])\n",
    "        gt_cs = _components(gt)\n",
    "        pr_cs = _components(pr)\n",
    "\n",
    "        if len(gt_cs) == 0 and len(pr_cs) == 0:\n",
    "            f1s.append(1.0)\n",
    "            continue\n",
    "        if len(gt_cs) == 0 or len(pr_cs) == 0:\n",
    "            f1s.append(0.0)\n",
    "            continue\n",
    "\n",
    "        IoU = np.zeros((len(gt_cs), len(pr_cs)), dtype=np.float32)\n",
    "        gt_areas = np.array([c.sum() for c in gt_cs], dtype=np.float32)\n",
    "        pr_areas = np.array([c.sum() for c in pr_cs], dtype=np.float32)\n",
    "\n",
    "        for g_idx, g in enumerate(gt_cs):\n",
    "            for p_idx, p in enumerate(pr_cs):\n",
    "                inter = np.logical_and(g, p).sum()\n",
    "                union = gt_areas[g_idx] + pr_areas[p_idx] - inter\n",
    "                IoU[g_idx, p_idx] = inter / (union + 1e-6)\n",
    "\n",
    "        matched_gt, matched_pr = set(), set()\n",
    "        pairs = []\n",
    "        all_pairs = [\n",
    "            (g, p)\n",
    "            for g in range(len(gt_cs))\n",
    "            for p in range(len(pr_cs))\n",
    "        ]\n",
    "        for g_idx, p_idx in sorted(all_pairs,\n",
    "                                   key=lambda x: IoU[x[0], x[1]],\n",
    "                                   reverse=True):\n",
    "            if (\n",
    "                IoU[g_idx, p_idx] >= iou_thresh\n",
    "                and g_idx not in matched_gt\n",
    "                and p_idx not in matched_pr\n",
    "            ):\n",
    "                matched_gt.add(g_idx)\n",
    "                matched_pr.add(p_idx)\n",
    "                pairs.append((g_idx, p_idx))\n",
    "\n",
    "        tp = len(pairs)\n",
    "        fp = len(pr_cs) - tp\n",
    "        fn = len(gt_cs) - tp\n",
    "        prec = tp / (tp + fp + 1e-6)\n",
    "        rec  = tp / (tp + fn + 1e-6)\n",
    "        f1   = (2 * prec * rec) / (prec + rec + 1e-6)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    return float(np.mean(f1s)), np.array(f1s)\n",
    "\n",
    "\n",
    "def evaluate_imbalanced(y_true, y_prob, t, tissue_masks=None, boundary_radius=2):\n",
    "    \"\"\"\n",
    "    Full evaluation suite for segmentation under severe class imbalance.\n",
    "\n",
    "    Computes:\n",
    "        - Dice (non-empty images only)\n",
    "        - Empty-image FP penalty\n",
    "        - Balanced Dice (average of the above two)\n",
    "        - Boundary F1 (edge detection)\n",
    "        - Lesion-level F1 (connected-component detection)\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Ground-truth masks [N,H,W,1].\n",
    "        y_prob (np.ndarray): Probability maps [N,H,W,1].\n",
    "        t (float): Threshold for binarization.\n",
    "        tissue_masks (np.ndarray or None):\n",
    "            Optional tissue-region masks for more accurate FP penalty.\n",
    "        boundary_radius (int): Thickness of boundary band.\n",
    "\n",
    "    Returns:\n",
    "        dict: Summary metrics + per-image arrays.\n",
    "    \"\"\"\n",
    "    y_pred = _threshold_probs(y_prob, t)\n",
    "\n",
    "    dice_pos_mean_val, dice_pos_all = dice_nonempty_mean(y_true, y_pred)\n",
    "    empty_pen_mean_val, empty_pen_all = empty_fp_penalty_mean(\n",
    "        y_true, y_pred, tissue_masks=tissue_masks\n",
    "    )\n",
    "    balanced_dice = 0.5 * (dice_pos_mean_val + empty_pen_mean_val)\n",
    "\n",
    "    b_f1_mean_val, b_f1_all = boundary_f1_mean(\n",
    "        y_true, y_pred, radius=boundary_radius\n",
    "    )\n",
    "    l_f1_mean_val, l_f1_all = lesion_f1_mean(\n",
    "        y_true, y_pred, iou_thresh=0.5\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"dice_pos_mean\": float(dice_pos_mean_val),\n",
    "        \"empty_penalty_mean\": float(empty_pen_mean_val),\n",
    "        \"balanced_dice\": float(balanced_dice),\n",
    "        \"boundary_f1_mean\": float(b_f1_mean_val),\n",
    "        \"lesion_f1_mean\": float(l_f1_mean_val),\n",
    "        \"per_image\": {\n",
    "            \"dice_pos\": dice_pos_all,\n",
    "            \"empty_penalty\": empty_pen_all,\n",
    "            \"boundary_f1\": b_f1_all,\n",
    "            \"lesion_f1\": l_f1_all,\n",
    "        },\n",
    "    }\n",
    "\n",
    "train_tissue_masks = None\n",
    "val_tissue_masks   = None\n",
    "test_tissue_masks  = None\n",
    "\n",
    "train_metrics = evaluate_imbalanced(Ytr, train_probs, t_star, tissue_masks=train_tissue_masks)\n",
    "val_metrics   = evaluate_imbalanced(Yva, val_probs,   t_star, tissue_masks=val_tissue_masks)\n",
    "test_metrics  = evaluate_imbalanced(Yte, test_probs,  t_star, tissue_masks=test_tissue_masks)\n",
    "\n",
    "print(\n",
    "    \"[TRAIN] dice_pos_mean={:.3f} | empty_penalty_mean={:.3f} | \"\n",
    "    \"balanced_dice={:.3f} | boundary_f1_mean={:.3f} | lesion_f1_mean={:.3f}\"\n",
    "    .format(\n",
    "        train_metrics[\"dice_pos_mean\"],\n",
    "        train_metrics[\"empty_penalty_mean\"],\n",
    "        train_metrics[\"balanced_dice\"],\n",
    "        train_metrics[\"boundary_f1_mean\"],\n",
    "        train_metrics[\"lesion_f1_mean\"],\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"\\n[VAL]  dice_pos_mean={:.3f} | empty_penalty_mean={:.3f} | \"\n",
    "    \"balanced_dice={:.3f} | boundary_f1_mean={:.3f} | lesion_f1_mean={:.3f}\"\n",
    "    .format(\n",
    "        val_metrics[\"dice_pos_mean\"],\n",
    "        val_metrics[\"empty_penalty_mean\"],\n",
    "        val_metrics[\"balanced_dice\"],\n",
    "        val_metrics[\"boundary_f1_mean\"],\n",
    "        val_metrics[\"lesion_f1_mean\"],\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"[TEST] dice_pos_mean={:.3f} | empty_penalty_mean={:.3f} | \"\n",
    "    \"balanced_dice={:.3f} | boundary_f1_mean={:.3f} | lesion_f1_mean={:.3f}\"\n",
    "    .format(\n",
    "        test_metrics[\"dice_pos_mean\"],\n",
    "        test_metrics[\"empty_penalty_mean\"],\n",
    "        test_metrics[\"balanced_dice\"],\n",
    "        test_metrics[\"boundary_f1_mean\"],\n",
    "        test_metrics[\"lesion_f1_mean\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc12477-a6d2-4ad4-bb4f-1034e6e834a0",
   "metadata": {},
   "source": [
    "# Filter Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b104042-6648-4256-910f-f1e4463009e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resolve_threshold(y_true, probs):\n",
    "    \"\"\"\n",
    "    Determines an appropriate segmentation threshold for probability maps,\n",
    "    preferring pre-calibrated global thresholds if available.\n",
    "\n",
    "    The function checks for globally defined variables in the following order:\n",
    "      1) t_star_calibrated\n",
    "      2) t_star\n",
    "    If neither is available or valid, it falls back to calibrating a threshold\n",
    "    on the provided (y_true, probs) pair using `best_dice_threshold`, if\n",
    "    defined. As a last resort, it returns 0.5.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): Ground-truth masks of shape (N, H, W, 1) or\n",
    "            (N, H, W), used if calibration is needed.\n",
    "        probs (numpy.ndarray): Predicted probability maps of shape\n",
    "            (N, H, W, 1) or (N, H, W).\n",
    "\n",
    "    Returns:\n",
    "        float: Selected threshold value in [0, 1] to be used for binarizing\n",
    "        `probs` into segmentation masks.\n",
    "    \"\"\"\n",
    "    # Prefer calibrated global thresholds if available\n",
    "    if \"t_star_calibrated\" in globals():\n",
    "        try:\n",
    "            return float(t_star_calibrated)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if \"t_star\" in globals():\n",
    "        try:\n",
    "            return float(t_star)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Otherwise calibrate on provided set (val/test) using  best_dice_threshold()\n",
    "    if \"best_dice_threshold\" in globals():\n",
    "        t_, _ = best_dice_threshold(y_true, probs)\n",
    "        return float(t_)\n",
    "    # Last resort\n",
    "    return 0.5\n",
    "\n",
    "# -- Helper: evaluate a probability map tensor at threshold t using evaluate() --\n",
    "def _eval_with_threshold(y_true, probs, t):\n",
    "    \"\"\"\n",
    "    Wrapper around `evaluate` to assess segmentation quality at a fixed\n",
    "    threshold.\n",
    "\n",
    "    This helper calls the global `evaluate(y_true, y_prob, t)` function and\n",
    "    simply forwards its output, allowing it to be used within ablation\n",
    "    experiments.\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): Ground-truth masks of shape (N, H, W, 1).\n",
    "        probs (numpy.ndarray): Predicted probability maps of shape\n",
    "            (N, H, W, 1).\n",
    "        t (float): Threshold in [0, 1] used to binarize `probs`.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A nested tuple containing:\n",
    "            - (float, float, float): Dice mean, standard deviation, and median.\n",
    "            - (float, float, float): IoU mean, standard deviation, and median.\n",
    "    \"\"\"\n",
    "    return evaluate(y_true, probs, t)\n",
    "\n",
    "# -- Optional: permutation within image (spatial shuffle) for a channel --\n",
    "def _permute_channel_inplace(x, chan, rng):\n",
    "    \"\"\"\n",
    "    Applies an in-place spatial permutation (shuffle) of one channel across\n",
    "    all images in a batch.\n",
    "\n",
    "    Each image's selected channel is flattened to 1D, shuffled independently\n",
    "    using the provided random number generator, and then reshaped back to\n",
    "    its original [H, W] structure. All other channels remain unchanged.\n",
    "\n",
    "    Args:\n",
    "        x (numpy.ndarray): Input tensor of shape (N, H, W, C) to be modified\n",
    "            in-place.\n",
    "        chan (int): Zero-based channel index to be permuted.\n",
    "        rng (numpy.random.RandomState): Random state used to perform the\n",
    "            shuffling, ensuring reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        None: The function modifies `x` in place.\n",
    "    \"\"\"\n",
    "    N, H, W, C = x.shape\n",
    "    flat = x[..., chan].reshape(N, -1)\n",
    "    for i in range(N):\n",
    "        rng.shuffle(flat[i])\n",
    "    x[..., chan] = flat.reshape(N, H, W)\n",
    "\n",
    "def run_filter_ablation(model, X, Y, batch_size=2, mode=\"zero\", repeats=1, seed=0, channel_map_1based=None):\n",
    "    \"\"\"\n",
    "    Performs per-channel ablation on the input voxel stack to estimate\n",
    "    filter/channel importance for a trained segmentation model.\n",
    "\n",
    "    Two ablation modes are supported:\n",
    "      - \"zero\":    Set the selected channel to zero for all pixels.\n",
    "      - \"permute\": Spatially shuffle the selected channel within each image,\n",
    "                   optionally repeating the experiment and averaging metrics.\n",
    "\n",
    "    For each channel, the function recomputes predictions, evaluates the\n",
    "    model at a fixed threshold (resolved by `_resolve_threshold`), and\n",
    "    records Dice and IoU drops relative to the unperturbed baseline.\n",
    "\n",
    "    If `KEEP_IDX` is defined globally, the function attempts to map channels\n",
    "    back to their original 1-based filter indices; otherwise, labels default\n",
    "    to [1..C].\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model or compatible): Trained segmentation model\n",
    "            with a `.predict()` method accepting inputs of shape (N, H, W, C).\n",
    "        X (numpy.ndarray): Input voxel tensor of shape (N, H, W, C) used\n",
    "            for evaluation (e.g., validation or test set).\n",
    "        Y (numpy.ndarray): Ground-truth masks of shape (N, H, W, 1).\n",
    "        batch_size (int, optional): Batch size for `model.predict`. Defaults to 2.\n",
    "        mode (str, optional): Ablation mode, either \"zero\" or \"permute\".\n",
    "            Defaults to \"zero\".\n",
    "        repeats (int, optional): Number of repeated permutations per channel\n",
    "            when `mode=\"permute\"`. Metrics are averaged across repeats.\n",
    "            Defaults to 1.\n",
    "        seed (int, optional): Random seed for reproducible permutations.\n",
    "            Defaults to 0.\n",
    "        channel_map_1based (list of int or None, optional): Optional mapping\n",
    "            from channel index (0-based) to original 1-based filter index.\n",
    "            If None, labels are set to [1..C], or derived from global\n",
    "            `KEEP_IDX` if present.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - pandas.DataFrame: Per-channel ablation summary with columns:\n",
    "                * 'chan_idx_0b'      : 0-based channel index\n",
    "                * 'chan_label_1b'    : 1-based channel label (original index)\n",
    "                * 'dice_mean'        : mean Dice after ablation\n",
    "                * 'dice_drop'        : Dice drop vs baseline\n",
    "                * 'iou_mean'         : mean IoU after ablation\n",
    "                * 'iou_drop'         : IoU drop vs baseline\n",
    "                * 'baseline_dice_mean': baseline Dice (no ablation)\n",
    "                * 'baseline_iou_mean' : baseline IoU (no ablation)\n",
    "                * 'threshold_used'   : threshold used for evaluation\n",
    "                * 'mode'             : ablation mode (\"zero\" or \"permute\")\n",
    "                * 'repeats'          : number of repeats (for permute mode)\n",
    "            - dict: Metadata dictionary containing:\n",
    "                * 'baseline': {'dice_mean', 'iou_mean', 't'}\n",
    "                * 'mode': ablation mode\n",
    "                * 'repeats': number of permutation repeats\n",
    "\n",
    "    Side Effects:\n",
    "        - Prints top and bottom 10 filters by Dice drop.\n",
    "        - Plots a bar chart of ΔDice for most and least impactful filters.\n",
    "        - Saves full results to 'filter_ablation_results.csv'.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Returns a pandas.DataFrame with per-channel metrics and drops vs baseline.\n",
    "    X: [N,H,W,C] input tensor used for evaluation (e.g., val or test stack)\n",
    "    Y: [N,H,W,1] ground-truth mask (float or uint8)\n",
    "    mode=\"zero\": set channel to 0\n",
    "    mode=\"permute\": spatially shuffle pixels of that channel within each image\n",
    "    \"\"\"\n",
    "    assert X.ndim == 4 and Y.ndim == 4 and X.shape[:3] == Y.shape[:3]\n",
    "    C = X.shape[-1]\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # Build nice channel labels\n",
    "    if channel_map_1based is None:\n",
    "        # Try to back-map to original selection if used KEEP_IDX; else fall back to 1..C\n",
    "        if \"KEEP_IDX\" in globals():\n",
    "            # KEEP_IDX are zero-based original indices; convert to 1-based labels\n",
    "            channel_map_1based = [int(i + 1) for i in list(KEEP_IDX)]\n",
    "        else:\n",
    "            channel_map_1based = list(range(1, C + 1))\n",
    "    assert len(channel_map_1based) == C, \"channel_map_1based length must match X[...,C]\"\n",
    "\n",
    "    # ---- Baseline ----\n",
    "    probs_base = model.predict(X, batch_size=batch_size)\n",
    "    t_use = _resolve_threshold(Y, probs_base)\n",
    "    (d_mean_b, d_std_b, d_med_b), (i_mean_b, i_std_b, i_med_b) = _eval_with_threshold(Y, probs_base, t_use)\n",
    "\n",
    "    rows = []\n",
    "    for c in range(C):\n",
    "        if mode == \"zero\":\n",
    "            X_mod = X.copy()\n",
    "            X_mod[..., c] = 0.0\n",
    "            probs_c = model.predict(X_mod, batch_size=batch_size)\n",
    "            (d_mean, d_std, d_med), (i_mean, i_std, i_med) = _eval_with_threshold(Y, probs_c, t_use)\n",
    "        elif mode == \"permute\":\n",
    "            d_means, i_means = [], []\n",
    "            for r in range(repeats):\n",
    "                X_mod = X.copy()\n",
    "                _permute_channel_inplace(X_mod, c, rng)\n",
    "                probs_c = model.predict(X_mod, batch_size=batch_size)\n",
    "                (d_mean, _, _), (i_mean, _, _) = _eval_with_threshold(Y, probs_c, t_use)\n",
    "                d_means.append(d_mean); i_means.append(i_mean)\n",
    "            # aggregate over repeats\n",
    "            d_mean = float(np.mean(d_means)); i_mean = float(np.mean(i_means))\n",
    "            # std over repeats for quick uncertainty (not pixel-level)\n",
    "            d_std, i_std = float(np.std(d_means)), float(np.std(i_means))\n",
    "            d_med = np.nan; i_med = np.nan  # (optional)\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'zero' or 'permute'\")\n",
    "\n",
    "        rows.append({\n",
    "            \"chan_idx_0b\": c,\n",
    "            \"chan_label_1b\": channel_map_1based[c],\n",
    "            \"dice_mean\": d_mean,\n",
    "            \"dice_drop\": d_mean_b - d_mean,\n",
    "            \"iou_mean\": i_mean,\n",
    "            \"iou_drop\": i_mean_b - i_mean,\n",
    "            \"baseline_dice_mean\": d_mean_b,\n",
    "            \"baseline_iou_mean\": i_mean_b,\n",
    "            \"threshold_used\": t_use,\n",
    "            \"mode\": mode,\n",
    "            \"repeats\": repeats\n",
    "        })\n",
    "\n",
    "    # ---- Aggregate results ----\n",
    "    df = (\n",
    "        pd.DataFrame(rows)\n",
    "        .sort_values(by=[\"dice_drop\", \"iou_drop\"], ascending=[False, False])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Nicely print both top and bottom 10 filters\n",
    "    with pd.option_context('display.max_rows', None, 'display.width', 120):\n",
    "        print(\"=== 10 Most Impactful Filters (largest Dice drop) ===\")\n",
    "        print(\n",
    "            df[[\n",
    "                \"chan_label_1b\", \"chan_idx_0b\",\n",
    "                \"dice_mean\", \"dice_drop\",\n",
    "                \"iou_mean\", \"iou_drop\",\n",
    "                \"threshold_used\", \"mode\"\n",
    "            ]].head(10)\n",
    "        )\n",
    "\n",
    "        print(\"\\n=== 10 Least Impactful Filters (smallest Dice drop) ===\")\n",
    "        print(\n",
    "            df[[\n",
    "                \"chan_label_1b\", \"chan_idx_0b\",\n",
    "                \"dice_mean\", \"dice_drop\",\n",
    "                \"iou_mean\", \"iou_drop\",\n",
    "                \"threshold_used\", \"mode\"\n",
    "            ]].tail(10)\n",
    "        )\n",
    "\n",
    "    # --- summarize ---\n",
    "    most10 = df.sort_values(\"dice_drop\", ascending=False).head(10)\n",
    "    least10 = df.sort_values(\"dice_drop\", ascending=True).head(10)\n",
    "    \n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(f\"Baseline Dice: {d_mean_b:.3f}\")\n",
    "    print(f\"Baseline IoU : {i_mean_b:.3f}\")\n",
    "    print(f\"Top filter impact range: {most10['dice_drop'].min():.3f}–{most10['dice_drop'].max():.3f}\")\n",
    "    print(f\"Least filter impact range: {least10['dice_drop'].min():.3f}–{least10['dice_drop'].max():.3f}\")\n",
    "    \n",
    "    # --- visualization ---\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(most10[\"chan_label_1b\"].astype(str), most10[\"dice_drop\"], color=\"salmon\", label=\"Most Impactful\")\n",
    "    plt.bar(least10[\"chan_label_1b\"].astype(str), least10[\"dice_drop\"], color=\"skyblue\", label=\"Least Impactful\")\n",
    "    plt.axhline(0, color=\"gray\", lw=1)\n",
    "    plt.xlabel(\"Channel Label (1-based)\")\n",
    "    plt.ylabel(\"ΔDice vs Baseline\")\n",
    "    plt.title(\"Filter Importance via Ablation\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- optional: export results to CSV ---\n",
    "    df.to_csv(\"filter_ablation_results.csv\", index=False)\n",
    "    print(\"\\nSaved full results to 'filter_ablation_results.csv'\")\n",
    "\n",
    "    return df, {\n",
    "        \"baseline\": {\"dice_mean\": d_mean_b, \"iou_mean\": i_mean_b, \"t\": t_use},\n",
    "        \"mode\": mode,\n",
    "        \"repeats\": repeats\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4863477-912e-4a60-a579-76b677822a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perm, meta_perm = run_filter_ablation(model=model, X=Xva_vox, =Yva.astype(np.float32), batch_size=2, mode=\"permute\", repeats=3, seed=123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
