{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6d273-a3c3-46aa-be5e-015d7d82f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import shutil\n",
    "import numpy as np\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from collections import defaultdict\n",
    "from sortedcontainers import SortedList\n",
    "from PIL import Image, ImageColor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    UpSampling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    Activation,\n",
    "    GlobalAveragePooling2D,\n",
    "    Reshape,\n",
    "    Lambda,\n",
    "    RandomRotation\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88233081-109d-477f-9ad5-c960b90b8291",
   "metadata": {},
   "source": [
    "# File Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b8ca21-70b6-4b78-8b9f-079c96866916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "# Define file paths\n",
    "BASE_PATH = \"data\"  # Store in 'data' folder\n",
    "FILENAME = \"image_dicts_256_wgrayscale_andcutoffs.pkl\"\n",
    "FILE_PATH = os.path.join(BASE_PATH, FILENAME)\n",
    "EXCEL_FILE_PATH = os.path.join(BASE_PATH, \"sample_groups.xlsx\")\n",
    "\n",
    "# GitHub release URL\n",
    "URL = \"https://github.com/tylervasse/DOCI-Prediction/releases/download/v1.0/image_dicts_256_wgrayscale_andcutoffs.pkl\"\n",
    "\n",
    "def download_file(url, output_path):\n",
    "    \"\"\"\n",
    "    Downloads a file from a URL if it doesn't already exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"Downloading {output_path}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        with open(output_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(f\"File already exists at {output_path}\")\n",
    "\n",
    "def load_image_dicts(file_path):\n",
    "    \"\"\"\n",
    "    Loads image dictionary data from a given file.\n",
    "    Parameters:\n",
    "        file_path (str): Path to the pickle file containing image dictionaries.\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing image metadata.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return pickle.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return []\n",
    "\n",
    "# Ensure the file is downloaded before loading\n",
    "download_file(URL, FILE_PATH)\n",
    "\n",
    "# Load image dictionaries\n",
    "image_dicts = load_image_dicts(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaff778-8c03-4b6e-ac99-1c1786bed172",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_list = [\"SSW-23-14395_C2\", \"SSW-23-05363_A7\"]\n",
    "\n",
    "for i in image_dicts:\n",
    "    image_dicts2 = [i for i in image_dicts if not any(exclude_word in i[\"name\"] for exclude_word in exclude_list)]\n",
    "\n",
    "image_dicts = image_dicts2\n",
    "\n",
    "EXCEL_FILE_PATH = 'data/sample_groups.xlsx'  # Ensure this file is in the correct directory\n",
    "\n",
    "def split_data(sample_names, train_ratio=0.6, val_ratio=0.4):\n",
    "    random.shuffle(sample_names)\n",
    "\n",
    "    # Calculate split indices\n",
    "    total_samples = len(sample_names)\n",
    "    train_end = int(total_samples * train_ratio)\n",
    "    val_end = train_end + int(total_samples * val_ratio)\n",
    "\n",
    "    # Create sets\n",
    "    train_samples = sample_names[:train_end]\n",
    "    val_samples = sample_names[train_end:val_end]\n",
    "    test_samples = sample_names[val_end:]\n",
    "\n",
    "    return train_samples, val_samples, test_samples\n",
    "\n",
    "def load_sample_groups(excel_file_path):\n",
    "    \"\"\"\n",
    "    Loads training, validation, and test sample groups from an Excel file.\n",
    "    Parameters:\n",
    "        excel_file_path (str): Path to the Excel file containing sample groups.\n",
    "    Returns:\n",
    "        tuple: Lists of training, validation, and test sample names.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        groups_df = pd.read_excel(excel_file_path)\n",
    "        train_samples = groups_df['Train Samples'].dropna().tolist()\n",
    "        train_samples = [str(sample).strip().replace(\"'\", \"\").replace(\" \", \"_\") for sample in train_samples]\n",
    "        val_samples = groups_df['Validation Samples'].dropna().tolist()\n",
    "        val_samples = [str(sample).strip().replace(\"'\", \"\").replace(\" \", \"_\") for sample in val_samples]\n",
    "        test_samples = groups_df['Test Samples'].dropna().tolist()\n",
    "        test_samples = [str(sample).strip().replace(\"'\", \"\").replace(\" \", \"_\") for sample in test_samples]\n",
    "        \n",
    "        return train_samples, val_samples, test_samples\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Sample groups file not found at {excel_file_path}\")\n",
    "        return [], [], []\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "        return [], [], []\n",
    "\n",
    "# Load sample groups\n",
    "train_samples, val_samples, test_samples = load_sample_groups(EXCEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704654d-1d45-4496-8bae-6adda1bdcf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PCA categories from Excel\n",
    "def load_pca_categories(file_path):\n",
    "    \"\"\"\n",
    "    Load PCA categories from an Excel file and return as lists.\n",
    "    Parameters:\n",
    "        file_path (str): Path to the Excel file containing PCA categories.\n",
    "    Returns:\n",
    "        tuple: Lists of PCA categories for follicular, papillary, and normal samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        pca_df = pd.read_excel(file_path)\n",
    "        pca_follicular = pca_df['PCA_follicular'].dropna().tolist()\n",
    "        pca_follicular = [str(sample).strip().replace(\"'\", \"\") for sample in pca_follicular]\n",
    "        pca_papillary = pca_df['PCA_papillary'].dropna().tolist()\n",
    "        pca_papillary = [str(sample).strip().replace(\"'\", \"\") for sample in pca_papillary]\n",
    "        pca_normal = pca_df['PCA_normal'].dropna().tolist()\n",
    "        pca_normal = [str(sample).strip().replace(\"'\", \"\") for sample in pca_normal]\n",
    "        return pca_follicular, pca_papillary, pca_normal\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return [], [], []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PCA categories: {e}\")\n",
    "        return [], [], []\n",
    "\n",
    "# Replace the path with the actual file path to your Excel file\n",
    "pca_file_path = 'data/pca_results.xlsx'\n",
    "pca_follicular, pca_papillary, pca_normal = load_pca_categories(pca_file_path)\n",
    "\n",
    "def categorize_images(image_data, train_samples, val_samples, test_samples):\n",
    "    \"\"\"\n",
    "    Categorizes images into training, validation, and test sets based on sample names.\n",
    "    Parameters:\n",
    "        image_data (list): List of dictionaries containing image metadata.\n",
    "        train_samples (list): List of sample names designated for training.\n",
    "        val_samples (list): List of sample names designated for validation.\n",
    "        test_samples (list): List of sample names designated for testing.\n",
    "    Returns:\n",
    "        tuple: Lists of categorized image data for training, validation, and testing.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_set, val_set, test_set = [], [], []\n",
    "    for data in image_data:\n",
    "        sample_name = data['name'].split('_')[0] + \"_\" + data['name'].split('_')[1]\n",
    "        if sample_name in train_samples:\n",
    "            train_set.append(data)\n",
    "        elif sample_name in val_samples:\n",
    "            val_set.append(data)\n",
    "        elif sample_name in test_samples:\n",
    "            test_set.append(data)\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "# Function to add PCA predictions\n",
    "def add_pca_predictions(rel_set, pca_follicular, pca_papillary, pca_normal):\n",
    "    \"\"\"\n",
    "    Adds PCA predictions as a 'tissue_type' key to the image metadata.\n",
    "    Parameters:\n",
    "        rel_set (list): List of dictionaries containing image metadata.\n",
    "        pca_follicular (list): List of follicular sample names.\n",
    "        pca_papillary (list): List of papillary sample names.\n",
    "        pca_normal (list): List of normal sample names.\n",
    "    Returns:\n",
    "        list: Updated list with added 'tissue_type' key.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_set = []\n",
    "    for i in rel_set:\n",
    "        name = i[\"name\"].split(\"_\")[0] + \"_\" + i[\"name\"].split(\"_\")[1]\n",
    "        if name in pca_follicular:\n",
    "            i[\"tissue_type\"] = \"Follicular\"\n",
    "        elif name in pca_papillary:\n",
    "            i[\"tissue_type\"] = \"Papillary\"\n",
    "        elif name in pca_normal:\n",
    "            i[\"tissue_type\"] = \"Normal\"\n",
    "        else:\n",
    "            i[\"tissue_type\"] = \"Unknown\"\n",
    "        new_set.append(i)\n",
    "    return new_set\n",
    "\n",
    "# Function to filter out specific tissue types\n",
    "def filter_out_relevant_predictions(rel_set, rel_cat):\n",
    "    \"\"\"\n",
    "    Filters out samples that match a specific tissue type.\n",
    "    Parameters:\n",
    "        rel_set (list): List of dictionaries containing image metadata with tissue types.\n",
    "        rel_cat (str): The tissue type to filter out.\n",
    "    Returns:\n",
    "        list: Filtered list excluding the specified tissue type.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [i for i in rel_set if i[\"tissue_type\"] != rel_cat]\n",
    "\n",
    "def include_filters(set1, include_list):\n",
    "    include_list = [f\"DOCI_{str(i)}.tif\" for i in include_list]\n",
    "    return [i for i in set1 if any(include_word in i[\"name\"] for include_word in include_list)]\n",
    "\n",
    "# Categorize images into training, validation, and test sets\n",
    "train_set, val_set, test_set = categorize_images(image_dicts, train_samples, val_samples, test_samples)\n",
    "\n",
    "# Add PCA predictions\n",
    "train_combined_with_predictions2 = add_pca_predictions(train_set, pca_follicular, pca_papillary, pca_normal)\n",
    "val_combined_with_predictions2 = add_pca_predictions(val_set, pca_follicular, pca_papillary, pca_normal)\n",
    "test_combined_with_predictions2 = add_pca_predictions(test_set, pca_follicular, pca_papillary, pca_normal)\n",
    "\n",
    "# Filter out 'Follicular' samples\n",
    "train_set = filter_out_relevant_predictions(train_combined_with_predictions2, \"Papillary\")\n",
    "val_set = filter_out_relevant_predictions(val_combined_with_predictions2, \"Papillary\")\n",
    "test_set = filter_out_relevant_predictions(test_combined_with_predictions2, \"Papillary\")\n",
    "\n",
    "#include_list = [2, 3, 4, 5, 6, 7, 8, 12, 16, 18, 21]\n",
    "#train_set = include_filters(train_set, include_list)\n",
    "#val_set = include_filters(val_set, include_list)\n",
    "#test_set = include_filters(test_set, include_list)\n",
    "\n",
    "# Shuffle the datasets\n",
    "train_set = shuffle(train_set, random_state=42)\n",
    "val_set = shuffle(val_set, random_state=42)\n",
    "test_set = shuffle(test_set, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d1a07-0776-43f8-ae70-dd616dc90b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to extract the base name before \"DOCI_n\"\n",
    "def get_base_name(name):\n",
    "    \"\"\"\n",
    "    Extracts the base name from a given file name before the \"DOCI_n\" part.\n",
    "    Parameters:\n",
    "        name (str): The full file name.\n",
    "    Returns:\n",
    "        str: The base name extracted from the file name.\n",
    "    \"\"\"\n",
    "    \n",
    "    return name.split('_DOCI')[0]\n",
    "\n",
    "# Function to extract the DOCI number (n) from the name\n",
    "def get_doci_number(name):\n",
    "    \"\"\"\n",
    "    Extracts the DOCI number (n) from a given file name.\n",
    "    Parameters:\n",
    "        name (str): The full file name.\n",
    "    Returns:\n",
    "        int: The extracted DOCI number, or -1 if no number is found.\n",
    "    \"\"\"\n",
    "    \n",
    "    match = re.search(r'_DOCI_(\\d+)', name)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "# Function to create a mask with 4 channels for each tissue type\n",
    "def create_mask_voxel(mask, tissue_type_index, num_classes=3):\n",
    "    \"\"\"\n",
    "    Creates a mask voxel with specified channels for each tissue type.\n",
    "    Parameters:\n",
    "        mask (numpy.ndarray): The binary mask for a single slice.\n",
    "        tissue_type_index (int): The index of the tissue type to activate in the voxel.\n",
    "        num_classes (int, optional): The total number of classes. Default is 3.\n",
    "    Returns:\n",
    "        numpy.ndarray: A voxel mask of shape (height, width, num_classes) with the tissue type channel activated.\n",
    "    \"\"\"\n",
    "    \n",
    "    mask_voxel = np.zeros((mask.shape[0], mask.shape[1], num_classes))\n",
    "    mask_voxel[:, :, tissue_type_index] = mask\n",
    "    return mask_voxel\n",
    "\n",
    "\n",
    "# Function to process a dataset (train, val, test)\n",
    "def process_dataset(dataset, tissue_types):\n",
    "    \"\"\"\n",
    "    Processes a dataset by grouping images based on the base name, sorting by DOCI number,\n",
    "    and creating voxelized grayscale and mask representations.\n",
    "    Parameters:\n",
    "        dataset (list): A list of dictionaries, where each dictionary contains metadata for a single image.\n",
    "        tissue_types (list): A list of tissue type labels.\n",
    "    Returns:\n",
    "        list: A list of voxelized samples, each containing grayscale voxels, tissue type, and a mask.\n",
    "    \"\"\"\n",
    "    \n",
    "    grouped_samples = defaultdict(lambda: {'images': [], 'image_cutoffs': [], 'tissue_type': None, 'masks': [], 'names': [],\n",
    "                                          'grayscale': [], 'image_grayscale_cutoff': []})\n",
    "    \n",
    "    # Group samples based on the base name\n",
    "    for sample in dataset:\n",
    "        base_name = get_base_name(sample['name'])\n",
    "        grouped_samples[base_name]['images'].append(sample['image'])\n",
    "        grouped_samples[base_name]['image_cutoffs'].append(sample['image_cutoff'])\n",
    "        grouped_samples[base_name]['tissue_type'] = sample['tissue_type']\n",
    "        grouped_samples[base_name]['masks'].append(sample['mask'])\n",
    "        grouped_samples[base_name]['names'].append(sample['name'])  # Store the name to extract DOCI number later\n",
    "        grouped_samples[base_name]['grayscale'].append(sample['grayscale'])\n",
    "        grouped_samples[base_name]['image_grayscale_cutoff'].append(sample['image_grayscale_cutoff'])\n",
    "    \n",
    "    # Convert images and image_cutoffs to grayscale and stack them to create voxels in the correct DOCI_n order\n",
    "    voxelized_samples = []\n",
    "    for base_name, group in grouped_samples.items():\n",
    "        # Sort by DOCI number\n",
    "        sorted_indices = sorted(range(len(group['names'])), key=lambda i: get_doci_number(group['names'][i]))\n",
    "        \n",
    "        # Sort images, image_cutoffs, and masks according to the sorted indices\n",
    "        sorted_images = [group['images'][i] for i in sorted_indices]\n",
    "        sorted_image_cutoffs = [group['image_cutoffs'][i] for i in sorted_indices]\n",
    "        sorted_masks = [group['masks'][i] for i in sorted_indices]\n",
    "        \n",
    "        sorted_grayscale = [group['grayscale'][i] for i in sorted_indices]\n",
    "        sorted_image_grayscale_cutoff = [group['image_grayscale_cutoff'][i] for i in sorted_indices]\n",
    "        \n",
    "        # Stack the grayscale images and image_cutoffs along the third dimension (axis=-1) to create voxels\n",
    "        grayscale_voxel = np.stack(sorted_grayscale, axis=-1)\n",
    "        grayscale_image_cutoff_voxel = np.stack(sorted_image_grayscale_cutoff, axis=-1)\n",
    "\n",
    "        # Create a mask voxel (256, 256, 4) based on the tissue type index\n",
    "        tissue_type_index = tissue_types.index(group['tissue_type'])\n",
    "        mask = group['masks'][0]\n",
    "        \n",
    "        # Create the voxelized sample\n",
    "        voxelized_sample = {\n",
    "            'name': base_name,\n",
    "            'grayscale_voxel': grayscale_voxel,\n",
    "            'grayscale_image_cutoff_voxel': grayscale_image_cutoff_voxel,\n",
    "            'tissue_type': group['tissue_type'],\n",
    "            'mask': mask\n",
    "        }\n",
    "        voxelized_samples.append(voxelized_sample)\n",
    "    \n",
    "    return voxelized_samples\n",
    "\n",
    "# Define the tissue types\n",
    "tissue_types = ['Normal', 'Follicular', 'Papillary', 'Anaplastic']\n",
    "\n",
    "# Process the train, val, and test sets to create voxels\n",
    "train_combined = process_dataset(train_set, tissue_types)\n",
    "val_combined = process_dataset(val_set, tissue_types)\n",
    "test_combined = process_dataset(test_set, tissue_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e42485c-9f68-4194-a69e-c9f575f1a9e3",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1804d0c2-9f9d-4676-bcde-81409f660588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentation function\n",
    "def augment(image, image_cutoff, mask):\n",
    "    \"\"\"\n",
    "    Applies random augmentations (flipping, rotation, zoom, and noise) to an image, \n",
    "    its cutoff version, and the associated mask.\n",
    "    Parameters:\n",
    "        image (tf.Tensor): The input image tensor.\n",
    "        image_cutoff (tf.Tensor): The cutoff version of the input image tensor.\n",
    "        mask (tf.Tensor): The mask tensor.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Augmented image, image_cutoff, and mask tensors.\n",
    "    \"\"\"\n",
    "    \n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image_cutoff = tf.cast(image_cutoff, tf.float32)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "    # Expand dimensions of the mask to make it 3D (256, 256, 1)\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    # Random augmentation parameters (same for image, image_cutoff, and mask)\n",
    "    flip_lr = tf.random.uniform(shape=[], minval=0, maxval=1, dtype=tf.float32)\n",
    "    flip_ud = tf.random.uniform(shape=[], minval=0, maxval=1, dtype=tf.float32)\n",
    "    angles = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    zoom_factor = tf.random.uniform([], 0.9, 1.1, dtype=tf.float32)\n",
    "\n",
    "    # Apply the same horizontal flip\n",
    "    image = tf.cond(flip_lr > 0.5, lambda: tf.image.flip_left_right(image), lambda: image)\n",
    "    image_cutoff = tf.cond(flip_lr > 0.5, lambda: tf.image.flip_left_right(image_cutoff), lambda: image_cutoff)\n",
    "    mask = tf.cond(flip_lr > 0.5, lambda: tf.image.flip_left_right(mask), lambda: mask)\n",
    "\n",
    "    # Apply the same vertical flip\n",
    "    image = tf.cond(flip_ud > 0.5, lambda: tf.image.flip_up_down(image), lambda: image)\n",
    "    image_cutoff = tf.cond(flip_ud > 0.5, lambda: tf.image.flip_up_down(image_cutoff), lambda: image_cutoff)\n",
    "    mask = tf.cond(flip_ud > 0.5, lambda: tf.image.flip_up_down(mask), lambda: mask)\n",
    "\n",
    "    # Apply the same rotation\n",
    "    image = tf.image.rot90(image, k=angles)\n",
    "    image_cutoff = tf.image.rot90(image_cutoff, k=angles)\n",
    "    mask = tf.image.rot90(mask, k=angles)\n",
    "\n",
    "    # Apply the same zoom\n",
    "    new_height = tf.cast(zoom_factor * tf.cast(tf.shape(image)[0], tf.float32), tf.int32)\n",
    "    new_width = tf.cast(zoom_factor * tf.cast(tf.shape(image)[1], tf.float32), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width])\n",
    "    image_cutoff = tf.image.resize(image_cutoff, [new_height, new_width])\n",
    "    mask = tf.image.resize(mask, [new_height, new_width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # Resize back to (256, 256)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 256, 256)\n",
    "    image_cutoff = tf.image.resize_with_crop_or_pad(image_cutoff, 256, 256)\n",
    "    mask = tf.image.resize_with_crop_or_pad(mask, 256, 256)\n",
    "\n",
    "    # Add random noise conditionally to image and image_cutoff\n",
    "    add_noise = tf.random.uniform(shape=[], minval=0, maxval=1, dtype=tf.float32)\n",
    "\n",
    "    def apply_noise(img):\n",
    "        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.001, dtype=tf.float32)\n",
    "        return img + noise\n",
    "    \n",
    "    image = tf.cond(add_noise > 0.5, lambda: apply_noise(image), lambda: image)\n",
    "    image_cutoff = tf.cond(add_noise > 0.5, lambda: apply_noise(image_cutoff), lambda: image_cutoff)\n",
    "\n",
    "    ## Squeeze the mask back to 2D (256, 256) if needed\n",
    "    mask = tf.squeeze(mask, axis=-1)\n",
    "\n",
    "    return image, image_cutoff, mask\n",
    "\n",
    "def load_image_and_masks(image, image_cutoff, mask, tissue_type_label, augment_data=False, num_augmentations=1):\n",
    "    \"\"\"\n",
    "    Normalizes and augments image, cutoff, and mask data for training, with reduced augmentations for 'Normal' tissue.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input grayscale image.\n",
    "        image_cutoff (numpy.ndarray): Input image cutoff.\n",
    "        mask (numpy.ndarray): Input mask.\n",
    "        tissue_type_label (str): Tissue type label.\n",
    "        augment_data (bool): Whether to augment the data.\n",
    "        num_augmentations (int): Base number of augmentations per sample if augment_data is True.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Lists of augmented images, image cutoffs, masks, and tissue type indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize image and image_cutoff\n",
    "    image = np.array(image) / 255.0\n",
    "    image_cutoff = np.array(image_cutoff) / 255.0\n",
    "\n",
    "    # Find the index of the tissue type\n",
    "    tissue_types = ['Normal', 'Follicular', 'Papillary', 'Anaplastic']\n",
    "    tissue_type_index = tissue_types.index(tissue_type_label)\n",
    "\n",
    "    images = [image]\n",
    "    image_cutoffs = [image_cutoff]\n",
    "    masks = [mask]\n",
    "    labels = [tissue_type_index]\n",
    "\n",
    "    # Adjust augmentations based on tissue type\n",
    "    if augment_data:\n",
    "        # Reduce augmentation factor for \"Normal\" tissue\n",
    "        #if tissue_type_label == \"Normal\":\n",
    "            #adjusted_augmentations = max(1, num_augmentations // 3)  # e.g., if 6 -> 2\n",
    "        #else:\n",
    "            #adjusted_augmentations = num_augmentations\n",
    "        adjusted_augmentations = num_augmentations ####\n",
    "        \n",
    "        for _ in range(adjusted_augmentations):\n",
    "            augmented_image, augmented_image_cutoff, augmented_mask = augment(image, image_cutoff, mask)\n",
    "            images.append(augmented_image)\n",
    "            image_cutoffs.append(augmented_image_cutoff)\n",
    "            masks.append(augmented_mask)\n",
    "            labels.append(tissue_type_index)\n",
    "\n",
    "    return images, image_cutoffs, masks, labels\n",
    "\n",
    "\n",
    "tissue_types = ['Normal', 'Follicular', 'Papillary']\n",
    "num_classes = len(tissue_types)\n",
    "\n",
    "\n",
    "# Function to resize voxel data (for both images and cutoffs)\n",
    "def resize_voxel(voxel, target_size=(256, 256), is_mask=False):\n",
    "    \"\"\"\n",
    "    Resizes voxel data to the specified target size.\n",
    "\n",
    "    Parameters:\n",
    "        voxel (numpy.ndarray): Input voxel data.\n",
    "        target_size (tuple): Target size for resizing (height, width).\n",
    "        is_mask (bool): Whether the voxel is a mask (for nearest-neighbor resizing).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Resized voxel data.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(voxel, tf.Tensor):\n",
    "        voxel = voxel.numpy()\n",
    "\n",
    "    if isinstance(voxel, np.ndarray):\n",
    "        if is_mask:\n",
    "            # Expand dimensions if the mask is 2D\n",
    "            if len(voxel.shape) == 2:\n",
    "                voxel = np.expand_dims(voxel, axis=-1)  # Add channel dimension\n",
    "            \n",
    "            # Resize the mask using nearest-neighbor to avoid introducing new values\n",
    "            voxel = tf.image.resize(voxel, target_size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR).numpy()\n",
    "            \n",
    "            # Squeeze back to 2D if it was originally 2D\n",
    "            voxel = np.squeeze(voxel, axis=-1)\n",
    "        else:\n",
    "            # Normal resizing for image and cutoff voxels\n",
    "            voxel = tf.image.resize(voxel, target_size).numpy()\n",
    "    \n",
    "    return voxel\n",
    "\n",
    "\n",
    "# Function to process a dataset (train, val, test)\n",
    "def process_dataset(dataset, augment_data=False, num_augmentations=1, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Processes a dataset to generate images, cutoffs, masks, and labels, with optional augmentation.\n",
    "    Parameters:\n",
    "        dataset (list): Input dataset containing image data and metadata.\n",
    "        augment_data (bool): Whether to apply augmentation to the dataset.\n",
    "        num_augmentations (int): Number of augmentations to apply per sample if augment_data is True.\n",
    "        target_size (tuple): Target size for resizing images and masks.\n",
    "    Returns:\n",
    "        tuple: Arrays of images, image cutoffs, masks, and labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    images, images_cutoffs, masks, labels = [], [], [], []\n",
    "\n",
    "    for img_dict in dataset:\n",
    "        # Load and augment the images, cutoffs, and masks\n",
    "        imgs, cutoffs, msks, lbls = load_image_and_masks(\n",
    "            img_dict['grayscale_voxel'], img_dict['grayscale_image_cutoff_voxel'], img_dict['mask'],\n",
    "            img_dict['tissue_type'],\n",
    "            augment_data=augment_data,\n",
    "            num_augmentations=num_augmentations\n",
    "        )\n",
    "\n",
    "        # Resize images, cutoffs, and masks if necessary\n",
    "        imgs = [resize_voxel(img, target_size) for img in imgs]\n",
    "        cutoffs = [resize_voxel(cutoff, target_size) for cutoff in cutoffs]\n",
    "        msks = [resize_voxel(mask, target_size, is_mask=True) for mask in msks]\n",
    "\n",
    "        images.extend(imgs)\n",
    "        images_cutoffs.extend(cutoffs)\n",
    "        masks.extend(msks)\n",
    "        labels.extend(lbls)\n",
    "\n",
    "    return np.array(images), np.array(images_cutoffs), np.array(masks), np.array(labels)\n",
    "\n",
    "# Process training data with augmentation\n",
    "train_images, train_images_cutoffs, train_masks, train_labels = process_dataset(\n",
    "    train_combined, augment_data=True, num_augmentations=6)\n",
    "\n",
    "# Process validation data without augmentation\n",
    "val_images, val_images_cutoffs, val_masks, val_labels = process_dataset(\n",
    "    val_combined, augment_data=False, num_augmentations=0)\n",
    "\n",
    "# Process test data without augmentation\n",
    "test_images, test_images_cutoffs, test_masks, test_labels = process_dataset(\n",
    "    test_combined, augment_data=False, num_augmentations=0)\n",
    "\n",
    "\n",
    "for i in range(len(train_combined)):\n",
    "    try:\n",
    "        train_combined[i][\"mask_voxel\"]\n",
    "    except:\n",
    "        train_combined[i][\"name\"]\n",
    "        \n",
    "train_masks = np.expand_dims(train_masks, axis=-1)\n",
    "val_masks = np.expand_dims(val_masks, axis=-1)\n",
    "test_masks = np.expand_dims(test_masks, axis=-1) \n",
    "\n",
    "def normalize_images(images):\n",
    "    \"\"\"\n",
    "    Normalizes images to the range [0, 1].\n",
    "    Parameters:\n",
    "        images (numpy.ndarray): Array of images.\n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized images.\n",
    "    \"\"\"\n",
    "    \n",
    "    if np.max(images) == 255:\n",
    "        images = images.astype('float32') / 255.0\n",
    "    return images\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_masks = np.array(train_masks)\n",
    "val_images = np.array(val_images)\n",
    "val_masks = np.array(val_masks)\n",
    "test_images = np.array(test_images)\n",
    "test_masks = np.array(test_masks)\n",
    "\n",
    "# Normalize to [0, 1] range\n",
    "train_images = normalize_images(train_images)\n",
    "val_images = normalize_images(val_images)\n",
    "test_images = normalize_images(test_images)\n",
    "\n",
    "train_masks = normalize_images(train_masks)\n",
    "val_masks= normalize_images(val_masks)\n",
    "test_masks = normalize_images(test_masks)\n",
    "\n",
    "# Verify the normalization\n",
    "print(f\"Train Images Min: {train_images.min()}, Max: {train_images.max()}\")\n",
    "print(f\"Val Images Min: {val_images.min()}, Max: {val_images.max()}\")\n",
    "print(f\"Test Images Min: {test_images.min()}, Max: {test_images.max()}\")\n",
    "\n",
    "print(f\"Train Masks Min: {train_masks.min()}, Max: {train_masks.max()}\")\n",
    "print(f\"Val Masks Min: {val_masks.min()}, Max: {val_masks.max()}\")\n",
    "print(f\"Test Masks Min: {test_masks.min()}, Max: {test_masks.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86625dc-02bd-4c52-9188-66bd4d7b4259",
   "metadata": {},
   "source": [
    "# U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d995a-fe12-4d56-95ce-2fa849bd77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the squeeze-and-excite block\n",
    "def squeeze_excite_block(input_tensor, ratio=16):\n",
    "    \"\"\"\n",
    "    Creates a squeeze-and-excite block that recalibrates the input tensor's channel-wise feature maps\n",
    "    by adaptively reweighting them.\n",
    "    Parameters:\n",
    "        input_tensor (tf.Tensor): The input tensor to the squeeze-and-excite block.\n",
    "        ratio (int, optional): The reduction ratio for channel-wise dimensionality reduction. Default is 16.\n",
    "    Returns:\n",
    "        tf.Tensor: The recalibrated tensor after applying squeeze-and-excite.\n",
    "    \"\"\"\n",
    "    \n",
    "    filters = input_tensor.shape[-1]\n",
    "    se = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    se = tf.keras.layers.Dense(filters // ratio, activation='relu')(se)\n",
    "    se = tf.keras.layers.Dense(filters, activation='sigmoid')(se)\n",
    "    se = tf.keras.layers.Reshape([1, 1, filters])(se)\n",
    "    return tf.keras.layers.multiply([input_tensor, se])\n",
    "\n",
    "# Define the encoder block\n",
    "def encoder_block(x, filters):\n",
    "    \"\"\"\n",
    "    Creates an encoder block consisting of convolutional layers, batch normalization, and down-sampling.\n",
    "    Parameters:\n",
    "        x (tf.Tensor): The input tensor to the encoder block.\n",
    "        filters (int): The number of filters for the convolutional layers.\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "        - tf.Tensor: The output tensor after the first convolution and batch normalization.\n",
    "        - tf.Tensor: The down-sampled tensor after the second convolution.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = squeeze_excite_block(x)\n",
    "    x_pool = Conv2D(filters, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    return x, x_pool\n",
    "\n",
    "# Define the decoder block\n",
    "def decoder_block(x, skip, filters):\n",
    "    \"\"\"\n",
    "    Creates a decoder block that upsamples the input tensor and merges it with the corresponding skip connection.\n",
    "    Parameters:\n",
    "        x (tf.Tensor): The input tensor to the decoder block.\n",
    "        skip (tf.Tensor): The skip connection tensor from the encoder block.\n",
    "        filters (int): The number of filters for the convolutional layers.\n",
    "    Returns:\n",
    "        tf.Tensor: The output tensor after upsampling, concatenation, and convolutional layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "# Combined Dice + BCE Loss\n",
    "def combined_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the combined Dice loss and Binary Cross-Entropy (BCE) loss.\n",
    "    Parameters:\n",
    "        y_true (tf.Tensor): Ground truth tensor.\n",
    "        y_pred (tf.Tensor): Predicted tensor.\n",
    "    Returns:\n",
    "        tf.Tensor: Combined loss value.\n",
    "    \"\"\"\n",
    "    \n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    bce = binary_crossentropy(y_true, tf.clip_by_value(y_pred, 0.0, 1.0))\n",
    "    return 0.5 * bce + 0.5 * dice\n",
    "\n",
    "# Dice Loss\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the Dice loss for segmentation tasks.\n",
    "    Parameters:\n",
    "        y_true (tf.Tensor): Ground truth tensor.\n",
    "        y_pred (tf.Tensor): Predicted tensor.\n",
    "    Returns:\n",
    "        tf.Tensor: Dice loss value.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    dice = 1 - (numerator + tf.keras.backend.epsilon()) / (denominator + tf.keras.backend.epsilon())\n",
    "    return tf.maximum(dice, 0)\n",
    "\n",
    "\n",
    "# Define the segmentation model architecture\n",
    "def build_u2net_with_rule(input_shape):\n",
    "    \"\"\"\n",
    "    Builds a U-Net-like segmentation model with additional dropout in the bottleneck and a custom loss function.\n",
    "    Parameters:\n",
    "        input_shape (tuple): The shape of the input tensor, including the number of channels.\n",
    "    Returns:\n",
    "        tf.keras.Model: A compiled U-Net-like segmentation model with a combined Dice and Binary Cross-Entropy (BCE) loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_input = Input(input_shape, name='image_input')\n",
    "\n",
    "    # Encoder\n",
    "    enc1, enc1_pool = encoder_block(image_input, 32)\n",
    "    enc2, enc2_pool = encoder_block(enc1_pool, 64)\n",
    "    #enc3, enc3_pool = encoder_block(enc2_pool, 128)\n",
    "\n",
    "    # Bottleneck\n",
    "    bottleneck = Conv2D(128, (3, 3), padding='same', activation='relu')(enc2_pool)\n",
    "    bottleneck = BatchNormalization()(bottleneck)\n",
    "    bottleneck = Dropout(0.7)(bottleneck)\n",
    "\n",
    "    # Decoder\n",
    "    #dec3 = decoder_block(bottleneck, enc3, 128)\n",
    "    dec2 = decoder_block(bottleneck, enc2, 64)\n",
    "    dec1 = decoder_block(dec2, enc1, 32)\n",
    "\n",
    "    # Segmentation mask output\n",
    "    seg_output = Conv2D(1, (1, 1), activation='sigmoid', name='seg_output')(dec1)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=image_input, outputs=seg_output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss=combined_loss,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define input shape with appended one-hot column\n",
    "input_shape = (256, 256, 23)\n",
    "\n",
    "# Build the model\n",
    "unet_segmentation_model = build_u2net_with_rule(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a184114-9b30-442b-8e9d-9f7fcf5e6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_models.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Combine callbacks\n",
    "callbacks = [early_stopping, checkpoint, reduce_lr]\n",
    "\n",
    "unet_segmentation_model.fit(\n",
    "    x=train_images,\n",
    "    y=train_masks,\n",
    "    validation_data=(val_images, val_masks),\n",
    "    batch_size=6,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc186d79-b977-4b20-bc5d-a125d827490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_segmentation_model.save('best_model.h5')\n",
    "test_loss, test_accuracy = unet_segmentation_model.evaluate(test_images, test_masks)\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
    "unet_segmentation_model.load_weights('best_model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85cafd-409f-4590-b415-21e5bf85ef16",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82627b-2c41-4240-ae2f-a6a5630e3603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(test_image, predicted_mask, actual_mask):\n",
    "    \"\"\"\n",
    "    Visualizes a side-by-side comparison of a test image, its predicted mask, and the ground truth mask.\n",
    "    Parameters:\n",
    "        test_image (numpy.ndarray): The input test image, expected to have at least 3 channels (height, width, channels).\n",
    "        predicted_mask (numpy.ndarray): The predicted mask, expected to have 3 dimensions (height, width, channels) with a single channel.\n",
    "        actual_mask (numpy.ndarray): The ground truth mask, expected to be a single-channel (2D) array.\n",
    "    Raises:\n",
    "        ValueError: If the actual_mask is not a single-channel (2D) array.\n",
    "    Returns:\n",
    "        None: Displays the comparison plots for visual inspection.\n",
    "    \"\"\"\n",
    "    \n",
    "    if actual_mask.ndim != 3:\n",
    "        raise ValueError(\"Actual mask is not a single-channel (2D) array.\")\n",
    "\n",
    "    # Visualize the comparison\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Plot the third channel in the image (index 2 for the third channel)\n",
    "    axs[0].imshow(test_image[:, :, 2], cmap='gray')\n",
    "    axs[0].set_title(\"DOCI Image\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Plot the predicted mask\n",
    "    axs[1].imshow(predicted_mask[:, :, 0], cmap='gray')\n",
    "    axs[1].set_title(\"Predicted Mask\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    # Plot the actual mask\n",
    "    axs[2].imshow(actual_mask, cmap='gray')\n",
    "    axs[2].set_title(\"Ground Truth Mask\")\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.savefig(\"1papillary.png\", dpi=400, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ab52e-5b20-4ba0-b1bb-7f6ea6aeca89",
   "metadata": {},
   "source": [
    "## Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd267cea-15a8-458a-8cd9-3bd6fae94e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_images)):\n",
    "    test_image = test_images[i]\n",
    "    actual_mask = test_masks[i]\n",
    "\n",
    "    # Predict the mask for the validation image\n",
    "    predicted_mask = unet_segmentation_model.predict(np.expand_dims(test_image, axis=0))[0]\n",
    "\n",
    "    # Visualize the third channel of the image, the predicted mask, and the actual mask\n",
    "    visualize_comparison(test_image, predicted_mask, actual_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6b8d1-f5f1-4e7b-bddc-2f204336a9ff",
   "metadata": {},
   "source": [
    "## Train Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68aa065-b408-4431-a860-8c0459d7983e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_images)):\n",
    "    train_image = train_images[i]\n",
    "    actual_mask = train_masks[i]\n",
    "\n",
    "    # Predict the mask for the validation image\n",
    "    predicted_mask = unet_segmentation_model.predict(np.expand_dims(train_image, axis=0))[0]\n",
    "\n",
    "    # Visualize the third channel of the image, the predicted mask, and the actual mask\n",
    "    visualize_comparison(train_image, predicted_mask, actual_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a587d8-7d8b-4861-9b51-ee7dc0078e4a",
   "metadata": {},
   "source": [
    "## Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc9fe3-7721-4f5f-ab87-4ab99f8b63b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the correct mask layer (only one has any true values)\n",
    "def find_true_mask_layer(mask):\n",
    "    \"\"\"\n",
    "    Identifies the index of the mask layer (channel) that contains non-zero (true) values.\n",
    "    This function iterates through the channels in the given mask and returns the index of the first \n",
    "    channel with any non-zero values. If no channel contains non-zero values, it defaults to returning 0.\n",
    "    Parameters:\n",
    "        mask (numpy.ndarray): A 3D array representing the mask (height, width, channels).\n",
    "    Returns:\n",
    "        int: The index of the first channel with non-zero values, or 0 if no non-zero values are found.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Iterate through each channel and find the first one with non-zero values\n",
    "    for i in range(mask.shape[-1]):\n",
    "        if np.any(mask[:, :, i]):\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "# Assuming the test_images, test_masks, and model are already loaded\n",
    "for i in range(len(val_images)):\n",
    "    val_image = val_images[i]\n",
    "    actual_mask = val_masks[i]\n",
    "\n",
    "    # Predict the mask for the test image voxel\n",
    "    predicted_mask = unet_segmentation_model.predict(np.expand_dims(val_image, axis=0))[0]\n",
    "\n",
    "    # Visualize the third image in the voxel, the predicted mask, and the actual mask for the true mask layer\n",
    "    visualize_comparison(val_image, predicted_mask, actual_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
